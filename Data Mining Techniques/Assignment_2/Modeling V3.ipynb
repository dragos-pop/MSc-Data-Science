{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import ndcg_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cleaned_train.csv\")\n",
    "test = pd.read_csv(\"cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [ \"comp1_rate\", \"comp1_inv\", \"comp2_rate\", \"comp2_inv\", \"comp3_rate\", \"comp3_inv\", \"comp4_rate\", \"comp4_inv\",\n",
    "                \"comp5_rate\", \"comp5_inv\", \"comp6_rate\", \"comp6_inv\", \"comp7_rate\", \"comp7_inv\", \"comp8_rate\", \"comp8_inv\",\n",
    "                \"weekday\", \"month\"]\n",
    "rest = [\"srch_id\", \"site_id\", \"visitor_location_country_id\", \"prop_country_id\", \"prop_id\", \"srch_destination_id\"]\n",
    "\n",
    "target = 'target_score' #click_bool in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group split needed for both train-test split and CV\n",
    "splitter = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state = 7)\n",
    "split = splitter.split(train, groups=train['srch_id'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train_df = train.iloc[train_inds]\n",
    "test_df = train.iloc[test_inds]\n",
    "\n",
    "X_train = train_df.drop([target], axis=1)\n",
    "X_test = test_df.drop([target], axis=1)\n",
    "y_train = train_df[target]\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pointwise LGBM regression (no tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 32.3 s, total: 3min 59s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the same model on whole train data\n",
    "model1.fit(train.drop([target], axis=1), train[target], categorical_feature=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 26.5 s, total: 3min 57s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04420504, -0.0808436 , -0.02696308, ..., -0.07440339,\n",
       "       -0.05211163, -0.05319732])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred1 = model1.predict(test)\n",
    "y_pred1 # 0,333 NDCG on public leaderboard when click_bool used + one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pointwise LGBM regression (hyperparameters tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(sorted_labels, k):\n",
    "    if k > 0:\n",
    "        k = min(sorted_labels.shape[0], k)\n",
    "    else:\n",
    "        k = sorted_labels.shape[0]\n",
    "    denom = 1./np.log2(np.arange(k)+2.)\n",
    "    nom = 2**sorted_labels-1.\n",
    "    dcg = np.sum(nom[:k]*denom)\n",
    "    return dcg\n",
    "\n",
    "def ndcg5(scores, labels):\n",
    "    sort_ind = np.argsort(scores)[::-1]\n",
    "    sorted_labels = labels[sort_ind]\n",
    "    ideal_labels = np.sort(labels)[::-1]\n",
    "    return dcg_at_k(sorted_labels, 5) / dcg_at_k(ideal_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = make_scorer(ndcg5, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune hyperparameters with groupKfold\n",
    "lgb_1 = lgb.LGBMRegressor()\n",
    "\n",
    "random_grid_params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15], \n",
    "    'n_estimators': [80, 100, 110, 120], \n",
    "    'min_child_samples': [17, 20, 23],\n",
    "    'num_leaves': [28, 31, 34],# large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type': [\"gbdt\", \"dart\", \"goss\"], # for better accuracy -> try dart\n",
    "    'max_bin': [255, 300],#large max_bin helps improve accuracy but might slow down training progress\n",
    "    'subsample': [1, 0.9],\n",
    "    'random_state': [42],\n",
    "    'verbose': [1]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(lgb_1, random_grid_params, n_iter=15, scoring=custom_scorer, cv=gss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.839569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.813442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.691823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.692600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.702240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.664507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.666929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.697444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.666874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.766089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.679989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.721086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.679127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.780817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.657359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.695249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.675269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.685326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.670929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.675534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.737586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.670039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.735676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.663189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.697302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.697458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.781756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.695855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.683206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.729892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.738931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.745404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.714499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.774484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.725112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.727009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.763313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.729538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.727899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.714501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.716362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.746388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.704980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.821477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.730349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.722221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.792265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.715929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.710484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61533\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.700971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61230\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.718808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61152\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.729502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61327\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044727\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.704201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61960\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346997, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044774\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.677110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61648\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345559, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.675678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61645\n",
      "[LightGBM] [Info] Number of data points in the train set: 3343685, number of used features: 99\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044803\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61749\n",
      "[LightGBM] [Info] Number of data points in the train set: 3347754, number of used features: 100\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -0.044727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.920931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54800\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044765\n",
      "CPU times: user 5h 52min 36s, sys: 29min, total: 6h 21min 37s\n",
      "Wall time: 2h 14min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=GroupShuffleSplit(n_splits=4, random_state=None, test_size=0.25,\n",
       "         train_size=None),\n",
       "                   estimator=LGBMRegressor(), n_iter=15,\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'dart',\n",
       "                                                          'goss'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15],\n",
       "                                        'max_bin': [255, 300],\n",
       "                                        'min_child_samples': [17, 20, 23],\n",
       "                                        'n_estimators': [80, 100, 110, 120],\n",
       "                                        'num_leaves': [28, 31, 34],\n",
       "                                        'random_state': [42],\n",
       "                                        'subsample': [1, 0.9], 'verbose': [1]},\n",
       "                   scoring=make_scorer(ndcg5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "random_search.fit(X_train, y_train, groups=X_train['srch_id'], categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'subsample': 1, 'random_state': 42, 'num_leaves': 34, 'n_estimators': 80, 'min_child_samples': 23, 'max_bin': 300, 'learning_rate': 0.1, 'boosting_type': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_2 = lgb.LGBMRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'learning_rate': [0.1], \n",
    "    'n_estimators': [75, 80, 85], \n",
    "    'min_child_samples': [23, 25],\n",
    "    'num_leaves': [34],\n",
    "    'boosting_type': ['dart'],\n",
    "    'max_bin': [300],\n",
    "    'subsample': [1],\n",
    "    'random_state': [42],\n",
    "    'verbose': [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lgb_2, grid_params, scoring=custom_scorer, cv=gss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.717730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.673973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.731776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.734519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.731770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.731279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.932101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.766713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.809531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.695559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.882626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.696699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.690181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.715231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.742902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.753455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.752869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.767947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 3344833, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044766\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.801284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61789\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346166, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044733\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.653004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61706\n",
      "[LightGBM] [Info] Number of data points in the train set: 3346502, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044745\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.672726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61870\n",
      "[LightGBM] [Info] Number of data points in the train set: 3345982, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -0.044820\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.900209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54800\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044765\n",
      "CPU times: user 2h 23s, sys: 12min 31s, total: 2h 12min 54s\n",
      "Wall time: 52min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=GroupShuffleSplit(n_splits=4, random_state=None, test_size=0.25,\n",
       "         train_size=None),\n",
       "             estimator=LGBMRegressor(),\n",
       "             param_grid={'boosting_type': ['dart'], 'learning_rate': [0.1],\n",
       "                         'max_bin': [300], 'min_child_samples': [23, 25],\n",
       "                         'n_estimators': [75, 80, 85], 'num_leaves': [34],\n",
       "                         'random_state': [42], 'subsample': [1],\n",
       "                         'verbose': [1]},\n",
       "             scoring=make_scorer(ndcg5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "grid_search.fit(X_train, y_train, groups=X_train['srch_id'], categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'dart', 'learning_rate': 0.1, 'max_bin': 300, 'min_child_samples': 23, 'n_estimators': 75, 'num_leaves': 34, 'random_state': 42, 'subsample': 1, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) model with best parameters on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = lgb.LGBMRegressor(boosting_type='dart', learning_rate= 0.1, max_bin= 300, min_child_samples= 23, n_estimators= 75, \n",
    "                            num_leaves= 34, random_state= 42, subsample= 1, verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.883699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54800\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044765\n",
      "CPU times: user 4min 57s, sys: 27 s, total: 5min 24s\n",
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', max_bin=300, min_child_samples=23,\n",
       "              n_estimators=75, num_leaves=34, random_state=42, subsample=1,\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit(X_train, y_train, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05891092, -0.02470499, -0.03123527, ..., -0.03825708,\n",
       "       -0.0381674 , -0.04850369])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>target_score</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058911</td>\n",
       "      <td>0.112061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.060242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.064423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055979</td>\n",
       "      <td>0.106572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.069378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.050058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.072143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.115072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032962</td>\n",
       "      <td>0.063475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084742</td>\n",
       "      <td>0.160428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048968</td>\n",
       "      <td>0.093444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.050058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>0.078629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.068405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.068405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.060242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.064423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118630</td>\n",
       "      <td>0.223878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>0.078629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040354</td>\n",
       "      <td>0.077315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033039</td>\n",
       "      <td>0.063620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048158</td>\n",
       "      <td>0.091928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.048015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.059925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  target_score  predictions  predictions_n\n",
       "119       12             0     0.058911       0.112061\n",
       "120       12             0     0.024705       0.048015\n",
       "121       12             0     0.031235       0.060242\n",
       "122       12             0     0.033468       0.064423\n",
       "123       12             0     0.055979       0.106572\n",
       "124       12             0     0.024705       0.048015\n",
       "125       12             0     0.024705       0.048015\n",
       "126       12             0     0.036114       0.069378\n",
       "127       12             0     0.025796       0.050058\n",
       "128       12             0     0.037591       0.072143\n",
       "129       12             0     0.024705       0.048015\n",
       "130       12             0     0.060519       0.115072\n",
       "131       12             0     0.032962       0.063475\n",
       "132       12             0     0.084742       0.160428\n",
       "133       12             0     0.048968       0.093444\n",
       "134       12             0     0.025796       0.050058\n",
       "135       12             0     0.024705       0.048015\n",
       "136       12             0     0.041055       0.078629\n",
       "137       12             0     0.035595       0.068405\n",
       "138       12             0     0.035595       0.068405\n",
       "139       12             0     0.031235       0.060242\n",
       "140       12             0     0.033468       0.064423\n",
       "141       12             0     0.118630       0.223878\n",
       "142       12             0     0.041055       0.078629\n",
       "143       12             0     0.040354       0.077315\n",
       "144       12             0     0.033039       0.063620\n",
       "145       12             1     0.048158       0.091928\n",
       "146       12             0     0.024705       0.048015\n",
       "207       25             0     0.031066       0.059925\n",
       "208       25             0     0.018448       0.036300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], -y_test], axis=1)\n",
    "df['predictions'] = -y_pred2\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6502984277660459\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "#     #t1\n",
    "#     a1 = [df[df[\"srch_id\"]==i][\"target_score\"].values]\n",
    "#     a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "#     scores.append(ndcg_score(a1, a2, k=5))\n",
    "\n",
    "    #t2 - better so far 0,5\n",
    "    a1 = df[df[\"srch_id\"]==i][\"target_score\"].values\n",
    "    a2 = df[df[\"srch_id\"]==i][\"predictions_n\"].values\n",
    "    scores.append(ndcg5(a1, a2))\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **) model with default parameters on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lgb.LGBMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 38.7 s, total: 4min 5s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_2.fit(X_train, y_train, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06094215, -0.0292679 , -0.04246334, ..., -0.03407786,\n",
       "       -0.05183003, -0.049999  ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>target_score</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.143452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.121284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>0.126686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.151360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.105626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.105847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048431</td>\n",
       "      <td>0.128443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031605</td>\n",
       "      <td>0.108258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054236</td>\n",
       "      <td>0.135407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>0.149856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.123244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>0.190343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.144765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045567</td>\n",
       "      <td>0.125007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059798</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.123995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.123577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.121284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049158</td>\n",
       "      <td>0.129316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>0.236934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>0.141859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.139178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048139</td>\n",
       "      <td>0.128093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055087</td>\n",
       "      <td>0.136428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.105106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032954</td>\n",
       "      <td>0.109877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.093556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  target_score  predictions  predictions_n\n",
       "119       12             0     0.060942       0.143452\n",
       "120       12             0     0.029268       0.105455\n",
       "121       12             0     0.042463       0.121284\n",
       "122       12             0     0.046966       0.126686\n",
       "123       12             0     0.067535       0.151360\n",
       "124       12             0     0.029410       0.105626\n",
       "125       12             0     0.029594       0.105847\n",
       "126       12             0     0.048431       0.128443\n",
       "127       12             0     0.031605       0.108258\n",
       "128       12             0     0.054236       0.135407\n",
       "129       12             0     0.029268       0.105455\n",
       "130       12             0     0.066281       0.149856\n",
       "131       12             0     0.044097       0.123244\n",
       "132       12             0     0.100030       0.190343\n",
       "133       12             0     0.062037       0.144765\n",
       "134       12             0     0.045567       0.125007\n",
       "135       12             0     0.029268       0.105455\n",
       "136       12             0     0.059798       0.142079\n",
       "137       12             0     0.044723       0.123995\n",
       "138       12             0     0.044374       0.123577\n",
       "139       12             0     0.042463       0.121284\n",
       "140       12             0     0.049158       0.129316\n",
       "141       12             0     0.138870       0.236934\n",
       "142       12             0     0.059614       0.141859\n",
       "143       12             0     0.057379       0.139178\n",
       "144       12             0     0.048139       0.128093\n",
       "145       12             1     0.055087       0.136428\n",
       "146       12             0     0.028977       0.105106\n",
       "207       25             0     0.032954       0.109877\n",
       "208       25             0     0.019349       0.093556"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], -y_test], axis=1)\n",
    "df['predictions'] = -y_pred_2\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7405544181973313\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "#     #t1\n",
    "#     a1 = [df[df[\"srch_id\"]==i][\"target_score\"].values]\n",
    "#     a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "#     scores.append(ndcg_score(a1, a2, k=5))\n",
    "\n",
    "    #t2 - better so far 0,5\n",
    "    a1 = df[df[\"srch_id\"]==i][\"target_score\"].values\n",
    "    a2 = df[df[\"srch_id\"]==i][\"predictions_n\"].values\n",
    "    scores.append(ndcg5(a1, a2))\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Model with best parameters on test data trained on training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.207171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 52285\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044749\n",
      "CPU times: user 5min 9s, sys: 50.1 s, total: 5min 59s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', max_bin=300, min_child_samples=23,\n",
       "              n_estimators=75, num_leaves=34, random_state=42, subsample=1,\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model3.fit(train.drop([target], axis=1), train[target], categorical_feature=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 34.5 s, total: 2min 6s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03317082, -0.07022708, -0.02995487, ..., -0.06802567,\n",
       "       -0.04854744, -0.04361254])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred3 = model3.predict(test)\n",
    "y_pred3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model with good parameters on test data trained on training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = lgb.LGBMRegressor(boosting_type='dart', learning_rate= 0.1, max_bin= 260, random_state= 42, verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.259687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 51907\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044749\n",
      "CPU times: user 7min 28s, sys: 51.5 s, total: 8min 20s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', max_bin=260, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model4.fit(train.drop([target], axis=1), train[target], categorical_feature=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 32.6 s, total: 2min 26s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03488449, -0.0692179 , -0.03125838, ..., -0.07318662,\n",
       "       -0.05010118, -0.04608794])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred4 = model4.predict(test)\n",
    "y_pred4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **) model with good parameters on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = lgb.LGBMRegressor(boosting_type='dart', learning_rate= 0.1, max_bin= 260, random_state= 42, verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.963698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54420\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.044765\n",
      "CPU times: user 6min 54s, sys: 48.2 s, total: 7min 42s\n",
      "Wall time: 3min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', max_bin=260, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_4.fit(X_train, y_train, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05791199, -0.02639941, -0.03381181, ..., -0.03913637,\n",
       "       -0.03873836, -0.05061529])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "y_pred_4 = model_4.predict(X_test)\n",
    "y_pred_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>target_score</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>0.100744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033812</td>\n",
       "      <td>0.058469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.063101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>0.102040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.068445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>0.047479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040725</td>\n",
       "      <td>0.070597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064334</td>\n",
       "      <td>0.112009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>0.062125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.153020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>0.089845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>0.047479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045464</td>\n",
       "      <td>0.078909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>0.065208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>0.065208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033812</td>\n",
       "      <td>0.058469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.063101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124597</td>\n",
       "      <td>0.217717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045464</td>\n",
       "      <td>0.078909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044771</td>\n",
       "      <td>0.077693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036182</td>\n",
       "      <td>0.062627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047863</td>\n",
       "      <td>0.083117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>0.056715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.034846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  target_score  predictions  predictions_n\n",
       "119       12             0     0.057912       0.100744\n",
       "120       12             0     0.026399       0.045467\n",
       "121       12             0     0.033812       0.058469\n",
       "122       12             0     0.036452       0.063101\n",
       "123       12             0     0.058651       0.102040\n",
       "124       12             0     0.026399       0.045467\n",
       "125       12             0     0.026399       0.045467\n",
       "126       12             0     0.039499       0.068445\n",
       "127       12             0     0.027546       0.047479\n",
       "128       12             0     0.040725       0.070597\n",
       "129       12             0     0.026399       0.045467\n",
       "130       12             0     0.064334       0.112009\n",
       "131       12             0     0.035896       0.062125\n",
       "132       12             0     0.087714       0.153020\n",
       "133       12             0     0.051699       0.089845\n",
       "134       12             0     0.027546       0.047479\n",
       "135       12             0     0.026399       0.045467\n",
       "136       12             0     0.045464       0.078909\n",
       "137       12             0     0.037654       0.065208\n",
       "138       12             0     0.037654       0.065208\n",
       "139       12             0     0.033812       0.058469\n",
       "140       12             0     0.036452       0.063101\n",
       "141       12             0     0.124597       0.217717\n",
       "142       12             0     0.045464       0.078909\n",
       "143       12             0     0.044771       0.077693\n",
       "144       12             0     0.036182       0.062627\n",
       "145       12             1     0.047863       0.083117\n",
       "146       12             0     0.026399       0.045467\n",
       "207       25             0     0.032812       0.056715\n",
       "208       25             0     0.020344       0.034846"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], -y_test], axis=1)\n",
    "df['predictions'] = -y_pred_4\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6483025578095043\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "#     #t1\n",
    "#     a1 = [df[df[\"srch_id\"]==i][\"target_score\"].values]\n",
    "#     a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "#     scores.append(ndcg_score(a1, a2, k=5))\n",
    "\n",
    "    #t2 - better so far 0,5\n",
    "    a1 = df[df[\"srch_id\"]==i][\"target_score\"].values\n",
    "    a2 = df[df[\"srch_id\"]==i][\"predictions_n\"].values\n",
    "    scores.append(ndcg5(a1, a2))\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **) Manually tried models with good parameters on validation data\n",
    "does not improve the ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = lgb.LGBMRegressor(n_estimators = 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 46.3 s, total: 4min 13s\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(n_estimators=105)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_5.fit(X_train, y_train, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "y_pred_5 = model_5.predict(X_test)\n",
    "# y_pred_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>target_score</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060821</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.105298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.121601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047238</td>\n",
       "      <td>0.127003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067728</td>\n",
       "      <td>0.151587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.105469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>0.105690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048792</td>\n",
       "      <td>0.128868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>0.108102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054612</td>\n",
       "      <td>0.135851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.105298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.149705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>0.123561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100407</td>\n",
       "      <td>0.190794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>0.145192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.125432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.105298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>0.142978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044602</td>\n",
       "      <td>0.123840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044253</td>\n",
       "      <td>0.123422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.121601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049913</td>\n",
       "      <td>0.130213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138749</td>\n",
       "      <td>0.236795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>0.142757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.139622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048515</td>\n",
       "      <td>0.128536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054966</td>\n",
       "      <td>0.136275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028856</td>\n",
       "      <td>0.104949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033242</td>\n",
       "      <td>0.110211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>0.093888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  target_score  predictions  predictions_n\n",
       "119       12             0     0.060821       0.143300\n",
       "120       12             0     0.029147       0.105298\n",
       "121       12             0     0.042735       0.121601\n",
       "122       12             0     0.047238       0.127003\n",
       "123       12             0     0.067728       0.151587\n",
       "124       12             0     0.029289       0.105469\n",
       "125       12             0     0.029473       0.105690\n",
       "126       12             0     0.048792       0.128868\n",
       "127       12             0     0.031484       0.108102\n",
       "128       12             0     0.054612       0.135851\n",
       "129       12             0     0.029147       0.105298\n",
       "130       12             0     0.066160       0.149705\n",
       "131       12             0     0.044368       0.123561\n",
       "132       12             0     0.100407       0.190794\n",
       "133       12             0     0.062398       0.145192\n",
       "134       12             0     0.045929       0.125432\n",
       "135       12             0     0.029147       0.105298\n",
       "136       12             0     0.060553       0.142978\n",
       "137       12             0     0.044602       0.123840\n",
       "138       12             0     0.044253       0.123422\n",
       "139       12             0     0.042735       0.121601\n",
       "140       12             0     0.049913       0.130213\n",
       "141       12             0     0.138749       0.236795\n",
       "142       12             0     0.060369       0.142757\n",
       "143       12             0     0.057756       0.139622\n",
       "144       12             0     0.048515       0.128536\n",
       "145       12             1     0.054966       0.136275\n",
       "146       12             0     0.028856       0.104949\n",
       "207       25             0     0.033242       0.110211\n",
       "208       25             0     0.019636       0.093888"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], -y_test], axis=1)\n",
    "df['predictions'] = -y_pred_5\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7384794825200066\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "#     #t1\n",
    "#     a1 = [df[df[\"srch_id\"]==i][\"target_score\"].values]\n",
    "#     a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "#     scores.append(ndcg_score(a1, a2, k=5))\n",
    "\n",
    "    #t2 - better so far 0,5\n",
    "    a1 = df[df[\"srch_id\"]==i][\"target_score\"].values\n",
    "    a2 = df[df[\"srch_id\"]==i][\"predictions_n\"].values\n",
    "    scores.append(ndcg5(a1, a2))\n",
    "print(sum(scores)/len(scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model with good parameters on test data trained on training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = lgb.LGBMRegressor(n_estimators = 105)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 50.3 s, total: 4min 26s\n",
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(n_estimators=105)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model5.fit(train.drop([target], axis=1), train[target], categorical_feature=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 37.1 s, total: 4min 27s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.05101309, -0.080704  , -0.02689009, ..., -0.07455775,\n",
       "       -0.05307171, -0.05305771])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred5 = model5.predict(test)\n",
    "y_pred5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Listwise: LGBMRanker with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = -y_train\n",
    "y_test_ = -y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "4958342    0\n",
       "4958343    0\n",
       "4958344    0\n",
       "4958345   -1\n",
       "4958346    0\n",
       "Name: target_score, Length: 4461236, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.935026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54305\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.299461\tvalid_1's ndcg@5: 0.292636\n",
      "[2]\ttraining's ndcg@5: 0.339943\tvalid_1's ndcg@5: 0.325278\n",
      "[3]\ttraining's ndcg@5: 0.352922\tvalid_1's ndcg@5: 0.333621\n",
      "[4]\ttraining's ndcg@5: 0.36205\tvalid_1's ndcg@5: 0.340558\n",
      "[5]\ttraining's ndcg@5: 0.367696\tvalid_1's ndcg@5: 0.346121\n",
      "[6]\ttraining's ndcg@5: 0.372135\tvalid_1's ndcg@5: 0.348248\n",
      "[7]\ttraining's ndcg@5: 0.37652\tvalid_1's ndcg@5: 0.351114\n",
      "[8]\ttraining's ndcg@5: 0.379403\tvalid_1's ndcg@5: 0.352944\n",
      "[9]\ttraining's ndcg@5: 0.382513\tvalid_1's ndcg@5: 0.354109\n",
      "[10]\ttraining's ndcg@5: 0.384195\tvalid_1's ndcg@5: 0.356146\n",
      "[11]\ttraining's ndcg@5: 0.387085\tvalid_1's ndcg@5: 0.357555\n",
      "[12]\ttraining's ndcg@5: 0.389873\tvalid_1's ndcg@5: 0.359794\n",
      "[13]\ttraining's ndcg@5: 0.392433\tvalid_1's ndcg@5: 0.360516\n",
      "[14]\ttraining's ndcg@5: 0.393826\tvalid_1's ndcg@5: 0.360487\n",
      "[15]\ttraining's ndcg@5: 0.397919\tvalid_1's ndcg@5: 0.363979\n",
      "[16]\ttraining's ndcg@5: 0.39977\tvalid_1's ndcg@5: 0.365685\n",
      "[17]\ttraining's ndcg@5: 0.400871\tvalid_1's ndcg@5: 0.366001\n",
      "[18]\ttraining's ndcg@5: 0.403141\tvalid_1's ndcg@5: 0.366552\n",
      "[19]\ttraining's ndcg@5: 0.404682\tvalid_1's ndcg@5: 0.366711\n",
      "[20]\ttraining's ndcg@5: 0.406064\tvalid_1's ndcg@5: 0.366995\n",
      "[21]\ttraining's ndcg@5: 0.407294\tvalid_1's ndcg@5: 0.367148\n",
      "[22]\ttraining's ndcg@5: 0.408342\tvalid_1's ndcg@5: 0.367164\n",
      "[23]\ttraining's ndcg@5: 0.41118\tvalid_1's ndcg@5: 0.369475\n",
      "[24]\ttraining's ndcg@5: 0.41214\tvalid_1's ndcg@5: 0.369639\n",
      "[25]\ttraining's ndcg@5: 0.413536\tvalid_1's ndcg@5: 0.37054\n",
      "[26]\ttraining's ndcg@5: 0.415496\tvalid_1's ndcg@5: 0.371322\n",
      "[27]\ttraining's ndcg@5: 0.416467\tvalid_1's ndcg@5: 0.371569\n",
      "[28]\ttraining's ndcg@5: 0.417954\tvalid_1's ndcg@5: 0.371365\n",
      "[29]\ttraining's ndcg@5: 0.419884\tvalid_1's ndcg@5: 0.372244\n",
      "[30]\ttraining's ndcg@5: 0.421168\tvalid_1's ndcg@5: 0.372486\n",
      "[31]\ttraining's ndcg@5: 0.42253\tvalid_1's ndcg@5: 0.373218\n",
      "[32]\ttraining's ndcg@5: 0.424188\tvalid_1's ndcg@5: 0.374424\n",
      "[33]\ttraining's ndcg@5: 0.42489\tvalid_1's ndcg@5: 0.374508\n",
      "[34]\ttraining's ndcg@5: 0.425894\tvalid_1's ndcg@5: 0.375227\n",
      "[35]\ttraining's ndcg@5: 0.426807\tvalid_1's ndcg@5: 0.375707\n",
      "[36]\ttraining's ndcg@5: 0.428073\tvalid_1's ndcg@5: 0.376192\n",
      "[37]\ttraining's ndcg@5: 0.429546\tvalid_1's ndcg@5: 0.375997\n",
      "[38]\ttraining's ndcg@5: 0.430552\tvalid_1's ndcg@5: 0.376615\n",
      "[39]\ttraining's ndcg@5: 0.431312\tvalid_1's ndcg@5: 0.376947\n",
      "[40]\ttraining's ndcg@5: 0.432126\tvalid_1's ndcg@5: 0.376667\n",
      "[41]\ttraining's ndcg@5: 0.432707\tvalid_1's ndcg@5: 0.377008\n",
      "[42]\ttraining's ndcg@5: 0.433896\tvalid_1's ndcg@5: 0.377125\n",
      "[43]\ttraining's ndcg@5: 0.435067\tvalid_1's ndcg@5: 0.377954\n",
      "[44]\ttraining's ndcg@5: 0.436064\tvalid_1's ndcg@5: 0.377682\n",
      "[45]\ttraining's ndcg@5: 0.43691\tvalid_1's ndcg@5: 0.377954\n",
      "[46]\ttraining's ndcg@5: 0.437732\tvalid_1's ndcg@5: 0.37844\n",
      "[47]\ttraining's ndcg@5: 0.43875\tvalid_1's ndcg@5: 0.378274\n",
      "[48]\ttraining's ndcg@5: 0.439632\tvalid_1's ndcg@5: 0.378636\n",
      "[49]\ttraining's ndcg@5: 0.440883\tvalid_1's ndcg@5: 0.379279\n",
      "[50]\ttraining's ndcg@5: 0.44179\tvalid_1's ndcg@5: 0.379186\n",
      "[51]\ttraining's ndcg@5: 0.442398\tvalid_1's ndcg@5: 0.37906\n",
      "[52]\ttraining's ndcg@5: 0.443705\tvalid_1's ndcg@5: 0.379241\n",
      "[53]\ttraining's ndcg@5: 0.444582\tvalid_1's ndcg@5: 0.379286\n",
      "[54]\ttraining's ndcg@5: 0.445039\tvalid_1's ndcg@5: 0.379455\n",
      "[55]\ttraining's ndcg@5: 0.445866\tvalid_1's ndcg@5: 0.380243\n",
      "[56]\ttraining's ndcg@5: 0.447151\tvalid_1's ndcg@5: 0.380137\n",
      "[57]\ttraining's ndcg@5: 0.447876\tvalid_1's ndcg@5: 0.380194\n",
      "[58]\ttraining's ndcg@5: 0.448689\tvalid_1's ndcg@5: 0.380495\n",
      "[59]\ttraining's ndcg@5: 0.449281\tvalid_1's ndcg@5: 0.380738\n",
      "[60]\ttraining's ndcg@5: 0.450461\tvalid_1's ndcg@5: 0.381084\n",
      "[61]\ttraining's ndcg@5: 0.450965\tvalid_1's ndcg@5: 0.380933\n",
      "[62]\ttraining's ndcg@5: 0.451767\tvalid_1's ndcg@5: 0.381039\n",
      "[63]\ttraining's ndcg@5: 0.452842\tvalid_1's ndcg@5: 0.38198\n",
      "[64]\ttraining's ndcg@5: 0.453302\tvalid_1's ndcg@5: 0.381626\n",
      "[65]\ttraining's ndcg@5: 0.453934\tvalid_1's ndcg@5: 0.382116\n",
      "[66]\ttraining's ndcg@5: 0.45461\tvalid_1's ndcg@5: 0.382232\n",
      "[67]\ttraining's ndcg@5: 0.455489\tvalid_1's ndcg@5: 0.382434\n",
      "[68]\ttraining's ndcg@5: 0.456243\tvalid_1's ndcg@5: 0.38243\n",
      "[69]\ttraining's ndcg@5: 0.456791\tvalid_1's ndcg@5: 0.382317\n",
      "[70]\ttraining's ndcg@5: 0.457566\tvalid_1's ndcg@5: 0.382534\n",
      "[71]\ttraining's ndcg@5: 0.458105\tvalid_1's ndcg@5: 0.382585\n",
      "[72]\ttraining's ndcg@5: 0.458509\tvalid_1's ndcg@5: 0.38311\n",
      "[73]\ttraining's ndcg@5: 0.459384\tvalid_1's ndcg@5: 0.382916\n",
      "[74]\ttraining's ndcg@5: 0.460413\tvalid_1's ndcg@5: 0.382991\n",
      "[75]\ttraining's ndcg@5: 0.461082\tvalid_1's ndcg@5: 0.383133\n",
      "[76]\ttraining's ndcg@5: 0.461534\tvalid_1's ndcg@5: 0.382778\n",
      "[77]\ttraining's ndcg@5: 0.462008\tvalid_1's ndcg@5: 0.383118\n",
      "[78]\ttraining's ndcg@5: 0.463065\tvalid_1's ndcg@5: 0.383748\n",
      "[79]\ttraining's ndcg@5: 0.463634\tvalid_1's ndcg@5: 0.384151\n",
      "[80]\ttraining's ndcg@5: 0.464354\tvalid_1's ndcg@5: 0.384122\n",
      "[81]\ttraining's ndcg@5: 0.464802\tvalid_1's ndcg@5: 0.384137\n",
      "[82]\ttraining's ndcg@5: 0.465441\tvalid_1's ndcg@5: 0.384113\n",
      "[83]\ttraining's ndcg@5: 0.466152\tvalid_1's ndcg@5: 0.384359\n",
      "[84]\ttraining's ndcg@5: 0.466867\tvalid_1's ndcg@5: 0.384906\n",
      "[85]\ttraining's ndcg@5: 0.467511\tvalid_1's ndcg@5: 0.385112\n",
      "[86]\ttraining's ndcg@5: 0.46786\tvalid_1's ndcg@5: 0.38507\n",
      "[87]\ttraining's ndcg@5: 0.468556\tvalid_1's ndcg@5: 0.385192\n",
      "[88]\ttraining's ndcg@5: 0.469232\tvalid_1's ndcg@5: 0.384946\n",
      "[89]\ttraining's ndcg@5: 0.469819\tvalid_1's ndcg@5: 0.385385\n",
      "[90]\ttraining's ndcg@5: 0.470432\tvalid_1's ndcg@5: 0.385679\n",
      "[91]\ttraining's ndcg@5: 0.470858\tvalid_1's ndcg@5: 0.385439\n",
      "[92]\ttraining's ndcg@5: 0.471585\tvalid_1's ndcg@5: 0.385524\n",
      "[93]\ttraining's ndcg@5: 0.472212\tvalid_1's ndcg@5: 0.385662\n",
      "[94]\ttraining's ndcg@5: 0.47291\tvalid_1's ndcg@5: 0.385421\n",
      "[95]\ttraining's ndcg@5: 0.473226\tvalid_1's ndcg@5: 0.385519\n",
      "[96]\ttraining's ndcg@5: 0.473866\tvalid_1's ndcg@5: 0.385753\n",
      "[97]\ttraining's ndcg@5: 0.474551\tvalid_1's ndcg@5: 0.385311\n",
      "[98]\ttraining's ndcg@5: 0.474959\tvalid_1's ndcg@5: 0.385523\n",
      "[99]\ttraining's ndcg@5: 0.475746\tvalid_1's ndcg@5: 0.385946\n",
      "[100]\ttraining's ndcg@5: 0.476284\tvalid_1's ndcg@5: 0.385938\n",
      "CPU times: user 4min 54s, sys: 34 s, total: 5min 28s\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(metric='ndcg', objective='lambdarank', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model6.fit(X_train, y_train_, eval_set=[(X_train, y_train_), (X_test, y_test_)], eval_group=[X_train['srch_id'].value_counts(sort=False).sort_index(), X_test['srch_id'].value_counts(sort=False).sort_index()], group=X_train['srch_id'].value_counts(sort=False).sort_index(),\n",
    "            eval_at=5,categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46175809, -0.7501605 , -0.54465082, ..., -0.26479785,\n",
       "        0.05585781,  0.35997866])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred6 = model6.predict(X_test)\n",
    "y_pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>target_score</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>0.506286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750161</td>\n",
       "      <td>0.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.544651</td>\n",
       "      <td>0.357319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.536805</td>\n",
       "      <td>0.358480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192074</td>\n",
       "      <td>0.466368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.639114</td>\n",
       "      <td>0.343336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.658146</td>\n",
       "      <td>0.340519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.320207</td>\n",
       "      <td>0.390541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.696013</td>\n",
       "      <td>0.334914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.215528</td>\n",
       "      <td>0.406035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.704841</td>\n",
       "      <td>0.333608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329605</td>\n",
       "      <td>0.486725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.661831</td>\n",
       "      <td>0.339974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515708</td>\n",
       "      <td>0.514272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400357</td>\n",
       "      <td>0.497198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.743673</td>\n",
       "      <td>0.327860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.679548</td>\n",
       "      <td>0.337352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231557</td>\n",
       "      <td>0.403663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.413938</td>\n",
       "      <td>0.376667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.413938</td>\n",
       "      <td>0.376667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.544651</td>\n",
       "      <td>0.357319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530346</td>\n",
       "      <td>0.359436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760235</td>\n",
       "      <td>0.550466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.255554</td>\n",
       "      <td>0.400111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.262295</td>\n",
       "      <td>0.399113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.432175</td>\n",
       "      <td>0.373967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321054</td>\n",
       "      <td>0.485459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.725411</td>\n",
       "      <td>0.330563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.267856</td>\n",
       "      <td>0.398290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.253260</td>\n",
       "      <td>0.252431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  target_score  predictions  predictions_n\n",
       "119       12             0     0.461758       0.506286\n",
       "120       12             0    -0.750161       0.326900\n",
       "121       12             0    -0.544651       0.357319\n",
       "122       12             0    -0.536805       0.358480\n",
       "123       12             0     0.192074       0.466368\n",
       "124       12             0    -0.639114       0.343336\n",
       "125       12             0    -0.658146       0.340519\n",
       "126       12             0    -0.320207       0.390541\n",
       "127       12             0    -0.696013       0.334914\n",
       "128       12             0    -0.215528       0.406035\n",
       "129       12             0    -0.704841       0.333608\n",
       "130       12             0     0.329605       0.486725\n",
       "131       12             0    -0.661831       0.339974\n",
       "132       12             0     0.515708       0.514272\n",
       "133       12             0     0.400357       0.497198\n",
       "134       12             0    -0.743673       0.327860\n",
       "135       12             0    -0.679548       0.337352\n",
       "136       12             0    -0.231557       0.403663\n",
       "137       12             0    -0.413938       0.376667\n",
       "138       12             0    -0.413938       0.376667\n",
       "139       12             0    -0.544651       0.357319\n",
       "140       12             0    -0.530346       0.359436\n",
       "141       12             0     0.760235       0.550466\n",
       "142       12             0    -0.255554       0.400111\n",
       "143       12             0    -0.262295       0.399113\n",
       "144       12             0    -0.432175       0.373967\n",
       "145       12             1     0.321054       0.485459\n",
       "146       12             0    -0.725411       0.330563\n",
       "207       25             0    -0.267856       0.398290\n",
       "208       25             0    -1.253260       0.252431"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], y_test_], axis=1)\n",
    "df['predictions'] = y_pred6\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919465816684291\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "#     #t1\n",
    "#     a1 = [df[df[\"srch_id\"]==i][\"target_score\"].values]\n",
    "#     a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "#     scores.append(ndcg_score(a1, a2, k=5))\n",
    "\n",
    "    #t2 - better so far 0,5\n",
    "    a1 = df[df[\"srch_id\"]==i][\"target_score\"].values\n",
    "    a2 = df[df[\"srch_id\"]==i][\"predictions_n\"].values\n",
    "    scores.append(ndcg5(a1, a2))\n",
    "print(sum(scores)/len(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- by target_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.461758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.544651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.192074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.639114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.658146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.320207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.696013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.215528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.704841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.329605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.661831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.515708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.400357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.743673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.679548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.231557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.413938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.413938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_score\n",
       "0      -0.461758\n",
       "1       0.750161\n",
       "2       0.544651\n",
       "3       0.536805\n",
       "4      -0.192074\n",
       "5       0.639114\n",
       "6       0.658146\n",
       "7       0.320207\n",
       "8       0.696013\n",
       "9       0.215528\n",
       "10      0.704841\n",
       "11     -0.329605\n",
       "12      0.661831\n",
       "13     -0.515708\n",
       "14     -0.400357\n",
       "15      0.743673\n",
       "16      0.679548\n",
       "17      0.231557\n",
       "18      0.413938\n",
       "19      0.413938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(data = -y_pred6, columns=['target_score'])\n",
    "r.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"srch_id\"] = test['srch_id']\n",
    "r[\"prop_id\"] = test['prop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.sort_values(['srch_id','target_score'])[[\"srch_id\",\"prop_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>95031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>63894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>72090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>61632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>128871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>54937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>78599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>99484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    srch_id  prop_id\n",
       "22        1    95031\n",
       "13        1    63894\n",
       "0         1     3180\n",
       "14        1    72090\n",
       "11        1    61632\n",
       "26        1   128871\n",
       "4         1    24194\n",
       "9         1    54937\n",
       "17        1    78599\n",
       "23        1    99484"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"sub9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
