{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import ndcg_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cleaned_train.csv\")\n",
    "test = pd.read_csv(\"cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [ \"comp1_rate\", \"comp1_inv\", \"comp2_rate\", \"comp2_inv\", \"comp3_rate\", \"comp3_inv\", \"comp4_rate\", \"comp4_inv\",\n",
    "                \"comp5_rate\", \"comp5_inv\", \"comp6_rate\", \"comp6_inv\", \"comp7_rate\", \"comp7_inv\", \"comp8_rate\", \"comp8_inv\",\n",
    "                \"weekday\", \"month\"]\n",
    "rest = [\"srch_id\", \"site_id\", \"visitor_location_country_id\", \"prop_country_id\", \"prop_id\", \"srch_destination_id\"]\n",
    "\n",
    "target = 'target_score' #click_bool in this case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg numeric features per srch_id\n",
    "numeric_cols = ['prop_starrating','prop_review_score','prop_location_score1','prop_location_score2',\n",
    "                'prop_log_historical_price','price_usd',]\n",
    "\n",
    "for i in numeric_cols:\n",
    "    name = i + '_avg'\n",
    "    train[name] = train.groupby(['srch_id'])[i].transform('mean')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_cols:\n",
    "    name = i + '_avg'\n",
    "    test[name] = test.groupby(['srch_id'])[i].transform('mean') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group split needed for both train-test split and CV\n",
    "splitter = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state = 7)\n",
    "split = splitter.split(train, groups=train['srch_id'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train_df = train.iloc[train_inds]\n",
    "test_df = train.iloc[test_inds]\n",
    "\n",
    "X_train = train_df.drop([target], axis=1)\n",
    "X_test = test_df.drop([target], axis=1)\n",
    "y_train = train_df[target]\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = make_scorer(ndcg_score, k=5, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **) model with default parameters on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lgb.LGBMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 32s, sys: 32.9 s, total: 4min 5s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_2.fit(X_train, y_train, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06094215, -0.0292679 , -0.04246334, ..., -0.03407786,\n",
       "       -0.05183003, -0.049999  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>position</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.143452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.121284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>0.126686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.151360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.105626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.105847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048431</td>\n",
       "      <td>0.128443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.031605</td>\n",
       "      <td>0.108258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.054236</td>\n",
       "      <td>0.135407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>0.149856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.123244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>0.190343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.144765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045567</td>\n",
       "      <td>0.125007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.105455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.059798</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.123995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.123577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.121284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.049158</td>\n",
       "      <td>0.129316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>0.236934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>0.141859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.057379</td>\n",
       "      <td>0.139178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.048139</td>\n",
       "      <td>0.128093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055087</td>\n",
       "      <td>0.136428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.105106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032954</td>\n",
       "      <td>0.109877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.093556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id  position  predictions  predictions_n\n",
       "119       12        25     0.060942       0.143452\n",
       "120       12        28     0.029268       0.105455\n",
       "121       12        24     0.042463       0.121284\n",
       "122       12        13     0.046966       0.126686\n",
       "123       12        18     0.067535       0.151360\n",
       "124       12         3     0.029410       0.105626\n",
       "125       12        14     0.029594       0.105847\n",
       "126       12         4     0.048431       0.128443\n",
       "127       12        22     0.031605       0.108258\n",
       "128       12        15     0.054236       0.135407\n",
       "129       12        26     0.029268       0.105455\n",
       "130       12        32     0.066281       0.149856\n",
       "131       12        19     0.044097       0.123244\n",
       "132       12         7     0.100030       0.190343\n",
       "133       12         9     0.062037       0.144765\n",
       "134       12         6     0.045567       0.125007\n",
       "135       12        29     0.029268       0.105455\n",
       "136       12         8     0.059798       0.142079\n",
       "137       12         2     0.044723       0.123995\n",
       "138       12        30     0.044374       0.123577\n",
       "139       12        27     0.042463       0.121284\n",
       "140       12        10     0.049158       0.129316\n",
       "141       12        21     0.138870       0.236934\n",
       "142       12        12     0.059614       0.141859\n",
       "143       12        16     0.057379       0.139178\n",
       "144       12        31     0.048139       0.128093\n",
       "145       12         1     0.055087       0.136428\n",
       "146       12        20     0.028977       0.105106\n",
       "207       25         1     0.032954       0.109877\n",
       "208       25        13     0.019349       0.093556"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], pos.iloc[test_inds]], axis=1)\n",
    "df['predictions'] = -y_pred_2\n",
    "df['predictions_n'] = (df['predictions']-df['predictions'].min())/(df['predictions'].max()-df['predictions'].min())\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3905902440826018\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "    a1 = [df[df[\"srch_id\"]==i][\"position\"].values]\n",
    "    a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values] \n",
    "    scores.append(ndcg_score(a1, a2, k=5)) \n",
    "print(sum(scores)/len(scores)) #0.39059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pointwise LGBM regression (no tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 32.3 s, total: 3min 59s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the same model on whole train data\n",
    "model1.fit(train.drop([target], axis=1), train[target], categorical_feature=rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 26.5 s, total: 3min 57s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04420504, -0.0808436 , -0.02696308, ..., -0.07440339,\n",
       "       -0.05211163, -0.05319732])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred1 = model1.predict(test)\n",
    "y_pred1 # 0,333 NDCG on public leaderboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Listwise: LGBMRanker with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = -y_train\n",
    "y_test_ = -y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['prop_country_id', 'prop_id', 'site_id', 'srch_destination_id', 'srch_id', 'visitor_location_country_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.939136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54305\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.299461\tvalid_1's ndcg@5: 0.292636\n",
      "[2]\ttraining's ndcg@5: 0.339943\tvalid_1's ndcg@5: 0.325278\n",
      "[3]\ttraining's ndcg@5: 0.352922\tvalid_1's ndcg@5: 0.333621\n",
      "[4]\ttraining's ndcg@5: 0.36205\tvalid_1's ndcg@5: 0.340558\n",
      "[5]\ttraining's ndcg@5: 0.367696\tvalid_1's ndcg@5: 0.346121\n",
      "[6]\ttraining's ndcg@5: 0.372135\tvalid_1's ndcg@5: 0.348248\n",
      "[7]\ttraining's ndcg@5: 0.37652\tvalid_1's ndcg@5: 0.351114\n",
      "[8]\ttraining's ndcg@5: 0.379403\tvalid_1's ndcg@5: 0.352944\n",
      "[9]\ttraining's ndcg@5: 0.382513\tvalid_1's ndcg@5: 0.354109\n",
      "[10]\ttraining's ndcg@5: 0.384195\tvalid_1's ndcg@5: 0.356146\n",
      "[11]\ttraining's ndcg@5: 0.387085\tvalid_1's ndcg@5: 0.357555\n",
      "[12]\ttraining's ndcg@5: 0.389873\tvalid_1's ndcg@5: 0.359794\n",
      "[13]\ttraining's ndcg@5: 0.392433\tvalid_1's ndcg@5: 0.360516\n",
      "[14]\ttraining's ndcg@5: 0.393826\tvalid_1's ndcg@5: 0.360487\n",
      "[15]\ttraining's ndcg@5: 0.397919\tvalid_1's ndcg@5: 0.363979\n",
      "[16]\ttraining's ndcg@5: 0.39977\tvalid_1's ndcg@5: 0.365685\n",
      "[17]\ttraining's ndcg@5: 0.400871\tvalid_1's ndcg@5: 0.366001\n",
      "[18]\ttraining's ndcg@5: 0.403141\tvalid_1's ndcg@5: 0.366552\n",
      "[19]\ttraining's ndcg@5: 0.404682\tvalid_1's ndcg@5: 0.366711\n",
      "[20]\ttraining's ndcg@5: 0.406064\tvalid_1's ndcg@5: 0.366995\n",
      "[21]\ttraining's ndcg@5: 0.407294\tvalid_1's ndcg@5: 0.367148\n",
      "[22]\ttraining's ndcg@5: 0.408342\tvalid_1's ndcg@5: 0.367164\n",
      "[23]\ttraining's ndcg@5: 0.41118\tvalid_1's ndcg@5: 0.369475\n",
      "[24]\ttraining's ndcg@5: 0.41214\tvalid_1's ndcg@5: 0.369639\n",
      "[25]\ttraining's ndcg@5: 0.413536\tvalid_1's ndcg@5: 0.37054\n",
      "[26]\ttraining's ndcg@5: 0.415496\tvalid_1's ndcg@5: 0.371322\n",
      "[27]\ttraining's ndcg@5: 0.416467\tvalid_1's ndcg@5: 0.371569\n",
      "[28]\ttraining's ndcg@5: 0.417954\tvalid_1's ndcg@5: 0.371365\n",
      "[29]\ttraining's ndcg@5: 0.419884\tvalid_1's ndcg@5: 0.372244\n",
      "[30]\ttraining's ndcg@5: 0.421168\tvalid_1's ndcg@5: 0.372486\n",
      "[31]\ttraining's ndcg@5: 0.42253\tvalid_1's ndcg@5: 0.373218\n",
      "[32]\ttraining's ndcg@5: 0.424188\tvalid_1's ndcg@5: 0.374424\n",
      "[33]\ttraining's ndcg@5: 0.42489\tvalid_1's ndcg@5: 0.374508\n",
      "[34]\ttraining's ndcg@5: 0.425894\tvalid_1's ndcg@5: 0.375227\n",
      "[35]\ttraining's ndcg@5: 0.426807\tvalid_1's ndcg@5: 0.375707\n",
      "[36]\ttraining's ndcg@5: 0.428073\tvalid_1's ndcg@5: 0.376192\n",
      "[37]\ttraining's ndcg@5: 0.429546\tvalid_1's ndcg@5: 0.375997\n",
      "[38]\ttraining's ndcg@5: 0.430552\tvalid_1's ndcg@5: 0.376615\n",
      "[39]\ttraining's ndcg@5: 0.431312\tvalid_1's ndcg@5: 0.376947\n",
      "[40]\ttraining's ndcg@5: 0.432126\tvalid_1's ndcg@5: 0.376667\n",
      "[41]\ttraining's ndcg@5: 0.432707\tvalid_1's ndcg@5: 0.377008\n",
      "[42]\ttraining's ndcg@5: 0.433896\tvalid_1's ndcg@5: 0.377125\n",
      "[43]\ttraining's ndcg@5: 0.435067\tvalid_1's ndcg@5: 0.377954\n",
      "[44]\ttraining's ndcg@5: 0.436064\tvalid_1's ndcg@5: 0.377682\n",
      "[45]\ttraining's ndcg@5: 0.43691\tvalid_1's ndcg@5: 0.377954\n",
      "[46]\ttraining's ndcg@5: 0.437732\tvalid_1's ndcg@5: 0.37844\n",
      "[47]\ttraining's ndcg@5: 0.43875\tvalid_1's ndcg@5: 0.378274\n",
      "[48]\ttraining's ndcg@5: 0.439632\tvalid_1's ndcg@5: 0.378636\n",
      "[49]\ttraining's ndcg@5: 0.440883\tvalid_1's ndcg@5: 0.379279\n",
      "[50]\ttraining's ndcg@5: 0.44179\tvalid_1's ndcg@5: 0.379186\n",
      "[51]\ttraining's ndcg@5: 0.442398\tvalid_1's ndcg@5: 0.37906\n",
      "[52]\ttraining's ndcg@5: 0.443705\tvalid_1's ndcg@5: 0.379241\n",
      "[53]\ttraining's ndcg@5: 0.444582\tvalid_1's ndcg@5: 0.379286\n",
      "[54]\ttraining's ndcg@5: 0.445039\tvalid_1's ndcg@5: 0.379455\n",
      "[55]\ttraining's ndcg@5: 0.445866\tvalid_1's ndcg@5: 0.380243\n",
      "[56]\ttraining's ndcg@5: 0.447151\tvalid_1's ndcg@5: 0.380137\n",
      "[57]\ttraining's ndcg@5: 0.447876\tvalid_1's ndcg@5: 0.380194\n",
      "[58]\ttraining's ndcg@5: 0.448689\tvalid_1's ndcg@5: 0.380495\n",
      "[59]\ttraining's ndcg@5: 0.449281\tvalid_1's ndcg@5: 0.380738\n",
      "[60]\ttraining's ndcg@5: 0.450461\tvalid_1's ndcg@5: 0.381084\n",
      "[61]\ttraining's ndcg@5: 0.450965\tvalid_1's ndcg@5: 0.380933\n",
      "[62]\ttraining's ndcg@5: 0.451767\tvalid_1's ndcg@5: 0.381039\n",
      "[63]\ttraining's ndcg@5: 0.452842\tvalid_1's ndcg@5: 0.38198\n",
      "[64]\ttraining's ndcg@5: 0.453302\tvalid_1's ndcg@5: 0.381626\n",
      "[65]\ttraining's ndcg@5: 0.453934\tvalid_1's ndcg@5: 0.382116\n",
      "[66]\ttraining's ndcg@5: 0.45461\tvalid_1's ndcg@5: 0.382232\n",
      "[67]\ttraining's ndcg@5: 0.455489\tvalid_1's ndcg@5: 0.382434\n",
      "[68]\ttraining's ndcg@5: 0.456243\tvalid_1's ndcg@5: 0.38243\n",
      "[69]\ttraining's ndcg@5: 0.456791\tvalid_1's ndcg@5: 0.382317\n",
      "[70]\ttraining's ndcg@5: 0.457566\tvalid_1's ndcg@5: 0.382534\n",
      "[71]\ttraining's ndcg@5: 0.458105\tvalid_1's ndcg@5: 0.382585\n",
      "[72]\ttraining's ndcg@5: 0.458509\tvalid_1's ndcg@5: 0.38311\n",
      "[73]\ttraining's ndcg@5: 0.459384\tvalid_1's ndcg@5: 0.382916\n",
      "[74]\ttraining's ndcg@5: 0.460413\tvalid_1's ndcg@5: 0.382991\n",
      "[75]\ttraining's ndcg@5: 0.461082\tvalid_1's ndcg@5: 0.383133\n",
      "[76]\ttraining's ndcg@5: 0.461534\tvalid_1's ndcg@5: 0.382778\n",
      "[77]\ttraining's ndcg@5: 0.462008\tvalid_1's ndcg@5: 0.383118\n",
      "[78]\ttraining's ndcg@5: 0.463065\tvalid_1's ndcg@5: 0.383748\n",
      "[79]\ttraining's ndcg@5: 0.463634\tvalid_1's ndcg@5: 0.384151\n",
      "[80]\ttraining's ndcg@5: 0.464354\tvalid_1's ndcg@5: 0.384122\n",
      "[81]\ttraining's ndcg@5: 0.464802\tvalid_1's ndcg@5: 0.384137\n",
      "[82]\ttraining's ndcg@5: 0.465441\tvalid_1's ndcg@5: 0.384113\n",
      "[83]\ttraining's ndcg@5: 0.466152\tvalid_1's ndcg@5: 0.384359\n",
      "[84]\ttraining's ndcg@5: 0.466867\tvalid_1's ndcg@5: 0.384906\n",
      "[85]\ttraining's ndcg@5: 0.467511\tvalid_1's ndcg@5: 0.385112\n",
      "[86]\ttraining's ndcg@5: 0.46786\tvalid_1's ndcg@5: 0.38507\n",
      "[87]\ttraining's ndcg@5: 0.468556\tvalid_1's ndcg@5: 0.385192\n",
      "[88]\ttraining's ndcg@5: 0.469232\tvalid_1's ndcg@5: 0.384946\n",
      "[89]\ttraining's ndcg@5: 0.469819\tvalid_1's ndcg@5: 0.385385\n",
      "[90]\ttraining's ndcg@5: 0.470432\tvalid_1's ndcg@5: 0.385679\n",
      "[91]\ttraining's ndcg@5: 0.470858\tvalid_1's ndcg@5: 0.385439\n",
      "[92]\ttraining's ndcg@5: 0.471585\tvalid_1's ndcg@5: 0.385524\n",
      "[93]\ttraining's ndcg@5: 0.472212\tvalid_1's ndcg@5: 0.385662\n",
      "[94]\ttraining's ndcg@5: 0.47291\tvalid_1's ndcg@5: 0.385421\n",
      "[95]\ttraining's ndcg@5: 0.473226\tvalid_1's ndcg@5: 0.385519\n",
      "[96]\ttraining's ndcg@5: 0.473866\tvalid_1's ndcg@5: 0.385753\n",
      "[97]\ttraining's ndcg@5: 0.474551\tvalid_1's ndcg@5: 0.385311\n",
      "[98]\ttraining's ndcg@5: 0.474959\tvalid_1's ndcg@5: 0.385523\n",
      "[99]\ttraining's ndcg@5: 0.475746\tvalid_1's ndcg@5: 0.385946\n",
      "[100]\ttraining's ndcg@5: 0.476284\tvalid_1's ndcg@5: 0.385938\n",
      "CPU times: user 4min 41s, sys: 40.5 s, total: 5min 21s\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(metric='ndcg', objective='lambdarank', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model6.fit(X_train, y_train_, eval_set=[(X_train, y_train_), (X_test, y_test_)], eval_group=[X_train['srch_id'].value_counts(sort=False).sort_index(), X_test['srch_id'].value_counts(sort=False).sort_index()], group=X_train['srch_id'].value_counts(sort=False).sort_index(),\n",
    "            eval_at=5,categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46175809, -0.7501605 , -0.54465082, ..., -0.26479785,\n",
       "        0.05585781,  0.35997866])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_6 = model6.predict(X_test)\n",
    "y_pred_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], pos.iloc[test_inds]], axis=1)\n",
    "df['predictions'] = y_pred_6\n",
    "# df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3724792233297772\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "    a1 = [df[df[\"srch_id\"]==i][\"position\"].values]\n",
    "    a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "    scores.append(ndcg_score(a1, a2, k=5))\n",
    "print(sum(scores)/len(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46165524,  0.88704194, -0.1051241 , ...,  0.01261689,\n",
       "        0.06631362,  0.17210367])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred6 = model6.predict(test)\n",
    "y_pred6 #scored 0,36 on public leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual try parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model66 = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1, num_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['prop_country_id', 'prop_id', 'site_id', 'srch_destination_id', 'srch_id', 'visitor_location_country_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.071674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 55835\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.296258\tvalid_1's ndcg@5: 0.291198\n",
      "[2]\ttraining's ndcg@5: 0.338184\tvalid_1's ndcg@5: 0.325807\n",
      "[3]\ttraining's ndcg@5: 0.352287\tvalid_1's ndcg@5: 0.335562\n",
      "[4]\ttraining's ndcg@5: 0.361074\tvalid_1's ndcg@5: 0.340977\n",
      "[5]\ttraining's ndcg@5: 0.366435\tvalid_1's ndcg@5: 0.343991\n",
      "[6]\ttraining's ndcg@5: 0.371134\tvalid_1's ndcg@5: 0.347469\n",
      "[7]\ttraining's ndcg@5: 0.376482\tvalid_1's ndcg@5: 0.349953\n",
      "[8]\ttraining's ndcg@5: 0.379578\tvalid_1's ndcg@5: 0.352844\n",
      "[9]\ttraining's ndcg@5: 0.382103\tvalid_1's ndcg@5: 0.35425\n",
      "[10]\ttraining's ndcg@5: 0.385151\tvalid_1's ndcg@5: 0.355526\n",
      "[11]\ttraining's ndcg@5: 0.386906\tvalid_1's ndcg@5: 0.35611\n",
      "[12]\ttraining's ndcg@5: 0.390398\tvalid_1's ndcg@5: 0.358514\n",
      "[13]\ttraining's ndcg@5: 0.39216\tvalid_1's ndcg@5: 0.358998\n",
      "[14]\ttraining's ndcg@5: 0.396545\tvalid_1's ndcg@5: 0.362194\n",
      "[15]\ttraining's ndcg@5: 0.398581\tvalid_1's ndcg@5: 0.363613\n",
      "[16]\ttraining's ndcg@5: 0.399811\tvalid_1's ndcg@5: 0.364139\n",
      "[17]\ttraining's ndcg@5: 0.401624\tvalid_1's ndcg@5: 0.364326\n",
      "[18]\ttraining's ndcg@5: 0.403041\tvalid_1's ndcg@5: 0.364385\n",
      "[19]\ttraining's ndcg@5: 0.404303\tvalid_1's ndcg@5: 0.36553\n",
      "[20]\ttraining's ndcg@5: 0.405795\tvalid_1's ndcg@5: 0.366863\n",
      "[21]\ttraining's ndcg@5: 0.407749\tvalid_1's ndcg@5: 0.367738\n",
      "[22]\ttraining's ndcg@5: 0.409899\tvalid_1's ndcg@5: 0.368629\n",
      "[23]\ttraining's ndcg@5: 0.411189\tvalid_1's ndcg@5: 0.368705\n",
      "[24]\ttraining's ndcg@5: 0.412512\tvalid_1's ndcg@5: 0.368396\n",
      "[25]\ttraining's ndcg@5: 0.413758\tvalid_1's ndcg@5: 0.369265\n",
      "[26]\ttraining's ndcg@5: 0.414882\tvalid_1's ndcg@5: 0.370174\n",
      "[27]\ttraining's ndcg@5: 0.417087\tvalid_1's ndcg@5: 0.371858\n",
      "[28]\ttraining's ndcg@5: 0.418207\tvalid_1's ndcg@5: 0.372173\n",
      "[29]\ttraining's ndcg@5: 0.419582\tvalid_1's ndcg@5: 0.371721\n",
      "[30]\ttraining's ndcg@5: 0.420808\tvalid_1's ndcg@5: 0.372523\n",
      "[31]\ttraining's ndcg@5: 0.421876\tvalid_1's ndcg@5: 0.371899\n",
      "[32]\ttraining's ndcg@5: 0.423414\tvalid_1's ndcg@5: 0.373147\n",
      "[33]\ttraining's ndcg@5: 0.424087\tvalid_1's ndcg@5: 0.373219\n",
      "[34]\ttraining's ndcg@5: 0.425586\tvalid_1's ndcg@5: 0.37394\n",
      "[35]\ttraining's ndcg@5: 0.426438\tvalid_1's ndcg@5: 0.374418\n",
      "[36]\ttraining's ndcg@5: 0.427399\tvalid_1's ndcg@5: 0.374573\n",
      "[37]\ttraining's ndcg@5: 0.428338\tvalid_1's ndcg@5: 0.375326\n",
      "[38]\ttraining's ndcg@5: 0.429964\tvalid_1's ndcg@5: 0.375953\n",
      "[39]\ttraining's ndcg@5: 0.431394\tvalid_1's ndcg@5: 0.377705\n",
      "[40]\ttraining's ndcg@5: 0.432314\tvalid_1's ndcg@5: 0.378105\n",
      "[41]\ttraining's ndcg@5: 0.433093\tvalid_1's ndcg@5: 0.377531\n",
      "[42]\ttraining's ndcg@5: 0.433856\tvalid_1's ndcg@5: 0.37762\n",
      "[43]\ttraining's ndcg@5: 0.435301\tvalid_1's ndcg@5: 0.378716\n",
      "[44]\ttraining's ndcg@5: 0.436161\tvalid_1's ndcg@5: 0.378519\n",
      "[45]\ttraining's ndcg@5: 0.436926\tvalid_1's ndcg@5: 0.378645\n",
      "[46]\ttraining's ndcg@5: 0.438054\tvalid_1's ndcg@5: 0.37879\n",
      "[47]\ttraining's ndcg@5: 0.439144\tvalid_1's ndcg@5: 0.378721\n",
      "[48]\ttraining's ndcg@5: 0.440269\tvalid_1's ndcg@5: 0.379018\n",
      "[49]\ttraining's ndcg@5: 0.440994\tvalid_1's ndcg@5: 0.378636\n",
      "[50]\ttraining's ndcg@5: 0.441783\tvalid_1's ndcg@5: 0.378475\n",
      "[51]\ttraining's ndcg@5: 0.442726\tvalid_1's ndcg@5: 0.379061\n",
      "[52]\ttraining's ndcg@5: 0.443295\tvalid_1's ndcg@5: 0.379306\n",
      "[53]\ttraining's ndcg@5: 0.444235\tvalid_1's ndcg@5: 0.379682\n",
      "[54]\ttraining's ndcg@5: 0.444723\tvalid_1's ndcg@5: 0.379929\n",
      "[55]\ttraining's ndcg@5: 0.445655\tvalid_1's ndcg@5: 0.380078\n",
      "[56]\ttraining's ndcg@5: 0.446586\tvalid_1's ndcg@5: 0.380309\n",
      "[57]\ttraining's ndcg@5: 0.447392\tvalid_1's ndcg@5: 0.380865\n",
      "[58]\ttraining's ndcg@5: 0.448312\tvalid_1's ndcg@5: 0.380709\n",
      "[59]\ttraining's ndcg@5: 0.448965\tvalid_1's ndcg@5: 0.380754\n",
      "[60]\ttraining's ndcg@5: 0.449913\tvalid_1's ndcg@5: 0.38121\n",
      "[61]\ttraining's ndcg@5: 0.45077\tvalid_1's ndcg@5: 0.381736\n",
      "[62]\ttraining's ndcg@5: 0.451414\tvalid_1's ndcg@5: 0.381674\n",
      "[63]\ttraining's ndcg@5: 0.45206\tvalid_1's ndcg@5: 0.382203\n",
      "[64]\ttraining's ndcg@5: 0.452892\tvalid_1's ndcg@5: 0.382033\n",
      "[65]\ttraining's ndcg@5: 0.453614\tvalid_1's ndcg@5: 0.382525\n",
      "[66]\ttraining's ndcg@5: 0.454327\tvalid_1's ndcg@5: 0.382204\n",
      "[67]\ttraining's ndcg@5: 0.455637\tvalid_1's ndcg@5: 0.382833\n",
      "[68]\ttraining's ndcg@5: 0.456096\tvalid_1's ndcg@5: 0.382853\n",
      "[69]\ttraining's ndcg@5: 0.456935\tvalid_1's ndcg@5: 0.382952\n",
      "[70]\ttraining's ndcg@5: 0.457601\tvalid_1's ndcg@5: 0.382987\n",
      "[71]\ttraining's ndcg@5: 0.458272\tvalid_1's ndcg@5: 0.383111\n",
      "[72]\ttraining's ndcg@5: 0.459148\tvalid_1's ndcg@5: 0.382843\n",
      "[73]\ttraining's ndcg@5: 0.45971\tvalid_1's ndcg@5: 0.383211\n",
      "[74]\ttraining's ndcg@5: 0.460582\tvalid_1's ndcg@5: 0.383864\n",
      "[75]\ttraining's ndcg@5: 0.461159\tvalid_1's ndcg@5: 0.383715\n",
      "[76]\ttraining's ndcg@5: 0.461645\tvalid_1's ndcg@5: 0.383433\n",
      "[77]\ttraining's ndcg@5: 0.46236\tvalid_1's ndcg@5: 0.383631\n",
      "[78]\ttraining's ndcg@5: 0.463059\tvalid_1's ndcg@5: 0.383965\n",
      "[79]\ttraining's ndcg@5: 0.463773\tvalid_1's ndcg@5: 0.38398\n",
      "[80]\ttraining's ndcg@5: 0.464213\tvalid_1's ndcg@5: 0.384097\n",
      "[81]\ttraining's ndcg@5: 0.4649\tvalid_1's ndcg@5: 0.384443\n",
      "[82]\ttraining's ndcg@5: 0.465841\tvalid_1's ndcg@5: 0.38452\n",
      "[83]\ttraining's ndcg@5: 0.466384\tvalid_1's ndcg@5: 0.384887\n",
      "[84]\ttraining's ndcg@5: 0.466757\tvalid_1's ndcg@5: 0.384466\n",
      "[85]\ttraining's ndcg@5: 0.467395\tvalid_1's ndcg@5: 0.384758\n",
      "[86]\ttraining's ndcg@5: 0.467927\tvalid_1's ndcg@5: 0.384809\n",
      "[87]\ttraining's ndcg@5: 0.468687\tvalid_1's ndcg@5: 0.38515\n",
      "[88]\ttraining's ndcg@5: 0.469403\tvalid_1's ndcg@5: 0.385279\n",
      "[89]\ttraining's ndcg@5: 0.470088\tvalid_1's ndcg@5: 0.385312\n",
      "[90]\ttraining's ndcg@5: 0.47056\tvalid_1's ndcg@5: 0.385611\n",
      "[91]\ttraining's ndcg@5: 0.471093\tvalid_1's ndcg@5: 0.385561\n",
      "[92]\ttraining's ndcg@5: 0.471857\tvalid_1's ndcg@5: 0.386028\n",
      "[93]\ttraining's ndcg@5: 0.472703\tvalid_1's ndcg@5: 0.386121\n",
      "[94]\ttraining's ndcg@5: 0.473302\tvalid_1's ndcg@5: 0.38635\n",
      "[95]\ttraining's ndcg@5: 0.473909\tvalid_1's ndcg@5: 0.386369\n",
      "[96]\ttraining's ndcg@5: 0.474391\tvalid_1's ndcg@5: 0.386251\n",
      "[97]\ttraining's ndcg@5: 0.474811\tvalid_1's ndcg@5: 0.386087\n",
      "[98]\ttraining's ndcg@5: 0.475172\tvalid_1's ndcg@5: 0.385844\n",
      "[99]\ttraining's ndcg@5: 0.475557\tvalid_1's ndcg@5: 0.385449\n",
      "[100]\ttraining's ndcg@5: 0.476156\tvalid_1's ndcg@5: 0.385935\n",
      "[101]\ttraining's ndcg@5: 0.476688\tvalid_1's ndcg@5: 0.38629\n",
      "[102]\ttraining's ndcg@5: 0.477282\tvalid_1's ndcg@5: 0.386581\n",
      "[103]\ttraining's ndcg@5: 0.478063\tvalid_1's ndcg@5: 0.386352\n",
      "[104]\ttraining's ndcg@5: 0.478573\tvalid_1's ndcg@5: 0.386482\n",
      "[105]\ttraining's ndcg@5: 0.479188\tvalid_1's ndcg@5: 0.386139\n",
      "[106]\ttraining's ndcg@5: 0.479632\tvalid_1's ndcg@5: 0.386185\n",
      "[107]\ttraining's ndcg@5: 0.480013\tvalid_1's ndcg@5: 0.385978\n",
      "[108]\ttraining's ndcg@5: 0.48045\tvalid_1's ndcg@5: 0.386225\n",
      "[109]\ttraining's ndcg@5: 0.481283\tvalid_1's ndcg@5: 0.386424\n",
      "[110]\ttraining's ndcg@5: 0.481792\tvalid_1's ndcg@5: 0.386384\n",
      "[111]\ttraining's ndcg@5: 0.482327\tvalid_1's ndcg@5: 0.386197\n",
      "[112]\ttraining's ndcg@5: 0.482857\tvalid_1's ndcg@5: 0.386164\n",
      "[113]\ttraining's ndcg@5: 0.483404\tvalid_1's ndcg@5: 0.38607\n",
      "[114]\ttraining's ndcg@5: 0.483788\tvalid_1's ndcg@5: 0.385933\n",
      "[115]\ttraining's ndcg@5: 0.484544\tvalid_1's ndcg@5: 0.386045\n",
      "[116]\ttraining's ndcg@5: 0.485048\tvalid_1's ndcg@5: 0.385657\n",
      "[117]\ttraining's ndcg@5: 0.485666\tvalid_1's ndcg@5: 0.385807\n",
      "[118]\ttraining's ndcg@5: 0.486177\tvalid_1's ndcg@5: 0.385784\n",
      "[119]\ttraining's ndcg@5: 0.486572\tvalid_1's ndcg@5: 0.386071\n",
      "[120]\ttraining's ndcg@5: 0.487111\tvalid_1's ndcg@5: 0.386235\n",
      "[121]\ttraining's ndcg@5: 0.48765\tvalid_1's ndcg@5: 0.386456\n",
      "[122]\ttraining's ndcg@5: 0.488121\tvalid_1's ndcg@5: 0.386459\n",
      "[123]\ttraining's ndcg@5: 0.488528\tvalid_1's ndcg@5: 0.386785\n",
      "[124]\ttraining's ndcg@5: 0.489207\tvalid_1's ndcg@5: 0.386965\n",
      "[125]\ttraining's ndcg@5: 0.48976\tvalid_1's ndcg@5: 0.387317\n",
      "[126]\ttraining's ndcg@5: 0.490076\tvalid_1's ndcg@5: 0.387442\n",
      "[127]\ttraining's ndcg@5: 0.490703\tvalid_1's ndcg@5: 0.387472\n",
      "[128]\ttraining's ndcg@5: 0.491143\tvalid_1's ndcg@5: 0.387541\n",
      "[129]\ttraining's ndcg@5: 0.491683\tvalid_1's ndcg@5: 0.387858\n",
      "[130]\ttraining's ndcg@5: 0.492116\tvalid_1's ndcg@5: 0.388025\n",
      "[131]\ttraining's ndcg@5: 0.49273\tvalid_1's ndcg@5: 0.388301\n",
      "[132]\ttraining's ndcg@5: 0.49296\tvalid_1's ndcg@5: 0.387953\n",
      "[133]\ttraining's ndcg@5: 0.493669\tvalid_1's ndcg@5: 0.387939\n",
      "[134]\ttraining's ndcg@5: 0.49404\tvalid_1's ndcg@5: 0.387873\n",
      "[135]\ttraining's ndcg@5: 0.494525\tvalid_1's ndcg@5: 0.38772\n",
      "[136]\ttraining's ndcg@5: 0.494979\tvalid_1's ndcg@5: 0.387946\n",
      "[137]\ttraining's ndcg@5: 0.495508\tvalid_1's ndcg@5: 0.388198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138]\ttraining's ndcg@5: 0.495981\tvalid_1's ndcg@5: 0.388184\n",
      "[139]\ttraining's ndcg@5: 0.496477\tvalid_1's ndcg@5: 0.388029\n",
      "[140]\ttraining's ndcg@5: 0.497054\tvalid_1's ndcg@5: 0.388069\n",
      "[141]\ttraining's ndcg@5: 0.497778\tvalid_1's ndcg@5: 0.388444\n",
      "[142]\ttraining's ndcg@5: 0.498252\tvalid_1's ndcg@5: 0.388266\n",
      "[143]\ttraining's ndcg@5: 0.498628\tvalid_1's ndcg@5: 0.388389\n",
      "[144]\ttraining's ndcg@5: 0.499009\tvalid_1's ndcg@5: 0.388348\n",
      "[145]\ttraining's ndcg@5: 0.499445\tvalid_1's ndcg@5: 0.388362\n",
      "[146]\ttraining's ndcg@5: 0.49973\tvalid_1's ndcg@5: 0.388216\n",
      "[147]\ttraining's ndcg@5: 0.500163\tvalid_1's ndcg@5: 0.388521\n",
      "[148]\ttraining's ndcg@5: 0.50077\tvalid_1's ndcg@5: 0.388348\n",
      "[149]\ttraining's ndcg@5: 0.501114\tvalid_1's ndcg@5: 0.38834\n",
      "[150]\ttraining's ndcg@5: 0.501566\tvalid_1's ndcg@5: 0.388351\n",
      "[151]\ttraining's ndcg@5: 0.502122\tvalid_1's ndcg@5: 0.388455\n",
      "[152]\ttraining's ndcg@5: 0.502449\tvalid_1's ndcg@5: 0.388471\n",
      "[153]\ttraining's ndcg@5: 0.502723\tvalid_1's ndcg@5: 0.388168\n",
      "[154]\ttraining's ndcg@5: 0.503165\tvalid_1's ndcg@5: 0.388393\n",
      "[155]\ttraining's ndcg@5: 0.503582\tvalid_1's ndcg@5: 0.38832\n",
      "[156]\ttraining's ndcg@5: 0.503959\tvalid_1's ndcg@5: 0.388522\n",
      "[157]\ttraining's ndcg@5: 0.504427\tvalid_1's ndcg@5: 0.38859\n",
      "[158]\ttraining's ndcg@5: 0.504754\tvalid_1's ndcg@5: 0.388632\n",
      "[159]\ttraining's ndcg@5: 0.505262\tvalid_1's ndcg@5: 0.388616\n",
      "[160]\ttraining's ndcg@5: 0.505669\tvalid_1's ndcg@5: 0.388629\n",
      "[161]\ttraining's ndcg@5: 0.506082\tvalid_1's ndcg@5: 0.388828\n",
      "[162]\ttraining's ndcg@5: 0.506499\tvalid_1's ndcg@5: 0.389049\n",
      "[163]\ttraining's ndcg@5: 0.506853\tvalid_1's ndcg@5: 0.388842\n",
      "[164]\ttraining's ndcg@5: 0.507279\tvalid_1's ndcg@5: 0.388931\n",
      "[165]\ttraining's ndcg@5: 0.507631\tvalid_1's ndcg@5: 0.388962\n",
      "[166]\ttraining's ndcg@5: 0.508022\tvalid_1's ndcg@5: 0.389208\n",
      "[167]\ttraining's ndcg@5: 0.508444\tvalid_1's ndcg@5: 0.389226\n",
      "[168]\ttraining's ndcg@5: 0.50898\tvalid_1's ndcg@5: 0.388968\n",
      "[169]\ttraining's ndcg@5: 0.509444\tvalid_1's ndcg@5: 0.388882\n",
      "[170]\ttraining's ndcg@5: 0.509674\tvalid_1's ndcg@5: 0.388687\n",
      "[171]\ttraining's ndcg@5: 0.510122\tvalid_1's ndcg@5: 0.388722\n",
      "[172]\ttraining's ndcg@5: 0.510364\tvalid_1's ndcg@5: 0.388453\n",
      "[173]\ttraining's ndcg@5: 0.51076\tvalid_1's ndcg@5: 0.388431\n",
      "[174]\ttraining's ndcg@5: 0.51117\tvalid_1's ndcg@5: 0.38832\n",
      "[175]\ttraining's ndcg@5: 0.511544\tvalid_1's ndcg@5: 0.388491\n",
      "[176]\ttraining's ndcg@5: 0.511906\tvalid_1's ndcg@5: 0.388677\n",
      "[177]\ttraining's ndcg@5: 0.512408\tvalid_1's ndcg@5: 0.388843\n",
      "[178]\ttraining's ndcg@5: 0.5127\tvalid_1's ndcg@5: 0.388868\n",
      "[179]\ttraining's ndcg@5: 0.513058\tvalid_1's ndcg@5: 0.389017\n",
      "[180]\ttraining's ndcg@5: 0.513358\tvalid_1's ndcg@5: 0.389078\n",
      "[181]\ttraining's ndcg@5: 0.513681\tvalid_1's ndcg@5: 0.389125\n",
      "[182]\ttraining's ndcg@5: 0.514036\tvalid_1's ndcg@5: 0.38912\n",
      "[183]\ttraining's ndcg@5: 0.514385\tvalid_1's ndcg@5: 0.389146\n",
      "[184]\ttraining's ndcg@5: 0.514733\tvalid_1's ndcg@5: 0.389363\n",
      "[185]\ttraining's ndcg@5: 0.515257\tvalid_1's ndcg@5: 0.389286\n",
      "[186]\ttraining's ndcg@5: 0.515695\tvalid_1's ndcg@5: 0.38915\n",
      "[187]\ttraining's ndcg@5: 0.516065\tvalid_1's ndcg@5: 0.389152\n",
      "[188]\ttraining's ndcg@5: 0.516434\tvalid_1's ndcg@5: 0.389106\n",
      "[189]\ttraining's ndcg@5: 0.516813\tvalid_1's ndcg@5: 0.389081\n",
      "[190]\ttraining's ndcg@5: 0.517193\tvalid_1's ndcg@5: 0.388694\n",
      "[191]\ttraining's ndcg@5: 0.517615\tvalid_1's ndcg@5: 0.388895\n",
      "[192]\ttraining's ndcg@5: 0.517987\tvalid_1's ndcg@5: 0.388974\n",
      "[193]\ttraining's ndcg@5: 0.518187\tvalid_1's ndcg@5: 0.38872\n",
      "[194]\ttraining's ndcg@5: 0.518495\tvalid_1's ndcg@5: 0.388789\n",
      "[195]\ttraining's ndcg@5: 0.519003\tvalid_1's ndcg@5: 0.388792\n",
      "[196]\ttraining's ndcg@5: 0.519243\tvalid_1's ndcg@5: 0.388782\n",
      "[197]\ttraining's ndcg@5: 0.519535\tvalid_1's ndcg@5: 0.388737\n",
      "[198]\ttraining's ndcg@5: 0.519836\tvalid_1's ndcg@5: 0.388877\n",
      "[199]\ttraining's ndcg@5: 0.520294\tvalid_1's ndcg@5: 0.38896\n",
      "[200]\ttraining's ndcg@5: 0.520626\tvalid_1's ndcg@5: 0.38903\n",
      "CPU times: user 9min 19s, sys: 39.9 s, total: 9min 59s\n",
      "Wall time: 3min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(metric='ndcg', num_iterations=200, objective='lambdarank', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model66.fit(X_train, y_train_, eval_set=[(X_train, y_train_), (X_test, y_test_)], eval_group=[X_train['srch_id'].value_counts(sort=False).sort_index(), X_test['srch_id'].value_counts(sort=False).sort_index()], group=X_train['srch_id'].value_counts(sort=False).sort_index(),\n",
    "            eval_at=5,categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47242995, -0.90038898, -0.56001683, ..., -0.48964774,\n",
       "        0.04473139,  0.50622928])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_66 = model66.predict(X_test)\n",
    "y_pred_66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], pos.iloc[test_inds]], axis=1)\n",
    "df['predictions'] = y_pred_66\n",
    "# df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37352776977571583\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "    a1 = [df[df[\"srch_id\"]==i][\"position\"].values]\n",
    "    a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "    scores.append(ndcg_score(a1, a2, k=5))\n",
    "print(sum(scores)/len(scores)) #0.3733667894875733 previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model66_ = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1, num_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.909351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53610\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 106\n",
      "CPU times: user 9min 12s, sys: 54.1 s, total: 10min 6s\n",
      "Wall time: 4min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(metric='ndcg', num_iterations=200, objective='lambdarank', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model66_.fit(train.drop([target], axis=1), -train[target], verbose=1,\n",
    "             group=train['srch_id'].value_counts(sort=False).sort_index(),categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 1s, sys: 39.9 s, total: 6min 41s\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.44716628,  0.91615011, -0.27887903, ...,  0.09441369,\n",
       "        0.05691774,  0.24926985])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred66 = model66_.predict(test)\n",
    "y_pred66 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Listwise: LGBMRanker with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = make_scorer(ndcg_score, k=5, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_11 = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_grid_params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15], \n",
    "    'n_estimators': [80, 100, 110, 120], \n",
    "    'min_child_samples': [17, 20, 23],\n",
    "    'num_leaves': [28, 31, 34],# large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type': [\"gbdt\", \"dart\", \"goss\"], # for better accuracy -> try dart\n",
    "    'max_bin': [255, 300],#large max_bin helps improve accuracy but might slow down training progress\n",
    "    'subsample': [1, 0.9],\n",
    "    'random_state': [42],\n",
    "    'verbose': [1]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(lgb_11, random_grid_params, n_iter=2, scoring=custom_scorer, cv=gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 977, in fit\n",
      "    super(LGBMRanker, self).fit(X, y, sample_weight=sample_weight,\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 612, in fit\n",
      "    self._Booster = train(params, train_set,\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\", line 231, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 2053, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 1321, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 1141, in _lazy_init\n",
      "    self.set_group(group)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 1713, in set_group\n",
      "    self.set_field('group', group)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 1485, in set_field\n",
      "    _safe_call(_LIB.LGBM_DatasetSetField(\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\", line 55, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Sum of query counts is not same with #data\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.931440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 55905\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 106\n",
      "CPU times: user 9min 51s, sys: 4min 39s, total: 14min 31s\n",
      "Wall time: 9min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=GroupShuffleSplit(n_splits=4, random_state=None, test_size=0.25,\n",
       "         train_size=None),\n",
       "                   estimator=LGBMRanker(metric='ndcg', objective='lambdarank',\n",
       "                                        verbose=1),\n",
       "                   n_iter=2,\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'dart',\n",
       "                                                          'goss'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15],\n",
       "                                        'max_bin': [255, 300],\n",
       "                                        'min_child_samples': [17, 20, 23],\n",
       "                                        'n_estimators': [80, 100, 110, 120],\n",
       "                                        'num_leaves': [28, 31, 34],\n",
       "                                        'random_state': [42],\n",
       "                                        'subsample': [1, 0.9], 'verbose': [1]},\n",
       "                   scoring=make_scorer(ndcg_score, k=5))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "random_search.fit(X_train, y_train_, groups=X_train['srch_id'], group=X_train['srch_id'].value_counts(sort=False).sort_index(),\n",
    "                  eval_at=5, categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1,\n",
       " 'subsample': 0.9,\n",
       " 'random_state': 42,\n",
       " 'num_leaves': 31,\n",
       " 'n_estimators': 120,\n",
       " 'min_child_samples': 20,\n",
       " 'max_bin': 255,\n",
       " 'learning_rate': 0.05,\n",
       " 'boosting_type': 'gbdt'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", verbose=1, subsample=0.9, learning_rate=0.05,\n",
    "                        n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['prop_country_id', 'prop_id', 'site_id', 'srch_destination_id', 'srch_id', 'visitor_location_country_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.112049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 55835\n",
      "[LightGBM] [Info] Number of data points in the train set: 4461236, number of used features: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.296258\tvalid_1's ndcg@5: 0.291198\n",
      "[2]\ttraining's ndcg@5: 0.338347\tvalid_1's ndcg@5: 0.325639\n",
      "[3]\ttraining's ndcg@5: 0.350967\tvalid_1's ndcg@5: 0.335463\n",
      "[4]\ttraining's ndcg@5: 0.358338\tvalid_1's ndcg@5: 0.340253\n",
      "[5]\ttraining's ndcg@5: 0.363304\tvalid_1's ndcg@5: 0.343129\n",
      "[6]\ttraining's ndcg@5: 0.367693\tvalid_1's ndcg@5: 0.34661\n",
      "[7]\ttraining's ndcg@5: 0.371235\tvalid_1's ndcg@5: 0.34854\n",
      "[8]\ttraining's ndcg@5: 0.376208\tvalid_1's ndcg@5: 0.352454\n",
      "[9]\ttraining's ndcg@5: 0.378396\tvalid_1's ndcg@5: 0.35293\n",
      "[10]\ttraining's ndcg@5: 0.38013\tvalid_1's ndcg@5: 0.353548\n",
      "[11]\ttraining's ndcg@5: 0.381131\tvalid_1's ndcg@5: 0.354361\n",
      "[12]\ttraining's ndcg@5: 0.383741\tvalid_1's ndcg@5: 0.357238\n",
      "[13]\ttraining's ndcg@5: 0.384683\tvalid_1's ndcg@5: 0.358202\n",
      "[14]\ttraining's ndcg@5: 0.386477\tvalid_1's ndcg@5: 0.358803\n",
      "[15]\ttraining's ndcg@5: 0.388247\tvalid_1's ndcg@5: 0.360052\n",
      "[16]\ttraining's ndcg@5: 0.389814\tvalid_1's ndcg@5: 0.360573\n",
      "[17]\ttraining's ndcg@5: 0.392594\tvalid_1's ndcg@5: 0.36261\n",
      "[18]\ttraining's ndcg@5: 0.393754\tvalid_1's ndcg@5: 0.363103\n",
      "[19]\ttraining's ndcg@5: 0.39449\tvalid_1's ndcg@5: 0.363076\n",
      "[20]\ttraining's ndcg@5: 0.394989\tvalid_1's ndcg@5: 0.363391\n",
      "[21]\ttraining's ndcg@5: 0.396003\tvalid_1's ndcg@5: 0.363323\n",
      "[22]\ttraining's ndcg@5: 0.397416\tvalid_1's ndcg@5: 0.364452\n",
      "[23]\ttraining's ndcg@5: 0.398801\tvalid_1's ndcg@5: 0.364869\n",
      "[24]\ttraining's ndcg@5: 0.399263\tvalid_1's ndcg@5: 0.365382\n",
      "[25]\ttraining's ndcg@5: 0.399876\tvalid_1's ndcg@5: 0.365668\n",
      "[26]\ttraining's ndcg@5: 0.401307\tvalid_1's ndcg@5: 0.366015\n",
      "[27]\ttraining's ndcg@5: 0.401971\tvalid_1's ndcg@5: 0.366264\n",
      "[28]\ttraining's ndcg@5: 0.402545\tvalid_1's ndcg@5: 0.366589\n",
      "[29]\ttraining's ndcg@5: 0.40385\tvalid_1's ndcg@5: 0.36747\n",
      "[30]\ttraining's ndcg@5: 0.404628\tvalid_1's ndcg@5: 0.367072\n",
      "[31]\ttraining's ndcg@5: 0.406226\tvalid_1's ndcg@5: 0.367984\n",
      "[32]\ttraining's ndcg@5: 0.406948\tvalid_1's ndcg@5: 0.36869\n",
      "[33]\ttraining's ndcg@5: 0.407402\tvalid_1's ndcg@5: 0.36865\n",
      "[34]\ttraining's ndcg@5: 0.407954\tvalid_1's ndcg@5: 0.368615\n",
      "[35]\ttraining's ndcg@5: 0.40853\tvalid_1's ndcg@5: 0.369353\n",
      "[36]\ttraining's ndcg@5: 0.410428\tvalid_1's ndcg@5: 0.370523\n",
      "[37]\ttraining's ndcg@5: 0.410955\tvalid_1's ndcg@5: 0.370777\n",
      "[38]\ttraining's ndcg@5: 0.411689\tvalid_1's ndcg@5: 0.370897\n",
      "[39]\ttraining's ndcg@5: 0.413504\tvalid_1's ndcg@5: 0.371649\n",
      "[40]\ttraining's ndcg@5: 0.413858\tvalid_1's ndcg@5: 0.371827\n",
      "[41]\ttraining's ndcg@5: 0.414459\tvalid_1's ndcg@5: 0.371817\n",
      "[42]\ttraining's ndcg@5: 0.415127\tvalid_1's ndcg@5: 0.371718\n",
      "[43]\ttraining's ndcg@5: 0.416407\tvalid_1's ndcg@5: 0.37215\n",
      "[44]\ttraining's ndcg@5: 0.416958\tvalid_1's ndcg@5: 0.372577\n",
      "[45]\ttraining's ndcg@5: 0.417612\tvalid_1's ndcg@5: 0.373155\n",
      "[46]\ttraining's ndcg@5: 0.418287\tvalid_1's ndcg@5: 0.372894\n",
      "[47]\ttraining's ndcg@5: 0.41899\tvalid_1's ndcg@5: 0.372862\n",
      "[48]\ttraining's ndcg@5: 0.419886\tvalid_1's ndcg@5: 0.373556\n",
      "[49]\ttraining's ndcg@5: 0.420535\tvalid_1's ndcg@5: 0.373372\n",
      "[50]\ttraining's ndcg@5: 0.421564\tvalid_1's ndcg@5: 0.373679\n",
      "[51]\ttraining's ndcg@5: 0.421984\tvalid_1's ndcg@5: 0.374011\n",
      "[52]\ttraining's ndcg@5: 0.422882\tvalid_1's ndcg@5: 0.374919\n",
      "[53]\ttraining's ndcg@5: 0.423277\tvalid_1's ndcg@5: 0.375052\n",
      "[54]\ttraining's ndcg@5: 0.423673\tvalid_1's ndcg@5: 0.374718\n",
      "[55]\ttraining's ndcg@5: 0.424043\tvalid_1's ndcg@5: 0.374822\n",
      "[56]\ttraining's ndcg@5: 0.425174\tvalid_1's ndcg@5: 0.375251\n",
      "[57]\ttraining's ndcg@5: 0.425882\tvalid_1's ndcg@5: 0.375709\n",
      "[58]\ttraining's ndcg@5: 0.426609\tvalid_1's ndcg@5: 0.375582\n",
      "[59]\ttraining's ndcg@5: 0.4269\tvalid_1's ndcg@5: 0.375743\n",
      "[60]\ttraining's ndcg@5: 0.427942\tvalid_1's ndcg@5: 0.375507\n",
      "[61]\ttraining's ndcg@5: 0.42831\tvalid_1's ndcg@5: 0.375895\n",
      "[62]\ttraining's ndcg@5: 0.42876\tvalid_1's ndcg@5: 0.375858\n",
      "[63]\ttraining's ndcg@5: 0.429948\tvalid_1's ndcg@5: 0.375962\n",
      "[64]\ttraining's ndcg@5: 0.43031\tvalid_1's ndcg@5: 0.375846\n",
      "[65]\ttraining's ndcg@5: 0.430659\tvalid_1's ndcg@5: 0.376275\n",
      "[66]\ttraining's ndcg@5: 0.431036\tvalid_1's ndcg@5: 0.376147\n",
      "[67]\ttraining's ndcg@5: 0.431778\tvalid_1's ndcg@5: 0.376508\n",
      "[68]\ttraining's ndcg@5: 0.432154\tvalid_1's ndcg@5: 0.3766\n",
      "[69]\ttraining's ndcg@5: 0.432775\tvalid_1's ndcg@5: 0.377439\n",
      "[70]\ttraining's ndcg@5: 0.433194\tvalid_1's ndcg@5: 0.377942\n",
      "[71]\ttraining's ndcg@5: 0.433657\tvalid_1's ndcg@5: 0.377455\n",
      "[72]\ttraining's ndcg@5: 0.434246\tvalid_1's ndcg@5: 0.378194\n",
      "[73]\ttraining's ndcg@5: 0.43481\tvalid_1's ndcg@5: 0.378201\n",
      "[74]\ttraining's ndcg@5: 0.435227\tvalid_1's ndcg@5: 0.377953\n",
      "[75]\ttraining's ndcg@5: 0.435771\tvalid_1's ndcg@5: 0.378151\n",
      "[76]\ttraining's ndcg@5: 0.436651\tvalid_1's ndcg@5: 0.378795\n",
      "[77]\ttraining's ndcg@5: 0.43713\tvalid_1's ndcg@5: 0.378795\n",
      "[78]\ttraining's ndcg@5: 0.437799\tvalid_1's ndcg@5: 0.378548\n",
      "[79]\ttraining's ndcg@5: 0.438153\tvalid_1's ndcg@5: 0.378448\n",
      "[80]\ttraining's ndcg@5: 0.438895\tvalid_1's ndcg@5: 0.378533\n",
      "[81]\ttraining's ndcg@5: 0.439328\tvalid_1's ndcg@5: 0.378479\n",
      "[82]\ttraining's ndcg@5: 0.43965\tvalid_1's ndcg@5: 0.378322\n",
      "[83]\ttraining's ndcg@5: 0.440337\tvalid_1's ndcg@5: 0.378953\n",
      "[84]\ttraining's ndcg@5: 0.440703\tvalid_1's ndcg@5: 0.378605\n",
      "[85]\ttraining's ndcg@5: 0.441318\tvalid_1's ndcg@5: 0.378914\n",
      "[86]\ttraining's ndcg@5: 0.441791\tvalid_1's ndcg@5: 0.379104\n",
      "[87]\ttraining's ndcg@5: 0.442387\tvalid_1's ndcg@5: 0.378808\n",
      "[88]\ttraining's ndcg@5: 0.442941\tvalid_1's ndcg@5: 0.379265\n",
      "[89]\ttraining's ndcg@5: 0.443617\tvalid_1's ndcg@5: 0.37945\n",
      "[90]\ttraining's ndcg@5: 0.443927\tvalid_1's ndcg@5: 0.379751\n",
      "[91]\ttraining's ndcg@5: 0.444117\tvalid_1's ndcg@5: 0.379672\n",
      "[92]\ttraining's ndcg@5: 0.444543\tvalid_1's ndcg@5: 0.379834\n",
      "[93]\ttraining's ndcg@5: 0.444984\tvalid_1's ndcg@5: 0.379431\n",
      "[94]\ttraining's ndcg@5: 0.445246\tvalid_1's ndcg@5: 0.379927\n",
      "[95]\ttraining's ndcg@5: 0.445842\tvalid_1's ndcg@5: 0.380202\n",
      "[96]\ttraining's ndcg@5: 0.446576\tvalid_1's ndcg@5: 0.380639\n",
      "[97]\ttraining's ndcg@5: 0.447029\tvalid_1's ndcg@5: 0.380863\n",
      "[98]\ttraining's ndcg@5: 0.447342\tvalid_1's ndcg@5: 0.380508\n",
      "[99]\ttraining's ndcg@5: 0.447775\tvalid_1's ndcg@5: 0.380441\n",
      "[100]\ttraining's ndcg@5: 0.448322\tvalid_1's ndcg@5: 0.380108\n",
      "[101]\ttraining's ndcg@5: 0.448648\tvalid_1's ndcg@5: 0.380387\n",
      "[102]\ttraining's ndcg@5: 0.448958\tvalid_1's ndcg@5: 0.380336\n",
      "[103]\ttraining's ndcg@5: 0.449423\tvalid_1's ndcg@5: 0.380651\n",
      "[104]\ttraining's ndcg@5: 0.450149\tvalid_1's ndcg@5: 0.380488\n",
      "[105]\ttraining's ndcg@5: 0.450756\tvalid_1's ndcg@5: 0.380463\n",
      "[106]\ttraining's ndcg@5: 0.451033\tvalid_1's ndcg@5: 0.380588\n",
      "[107]\ttraining's ndcg@5: 0.451345\tvalid_1's ndcg@5: 0.380716\n",
      "[108]\ttraining's ndcg@5: 0.451628\tvalid_1's ndcg@5: 0.380721\n",
      "[109]\ttraining's ndcg@5: 0.452021\tvalid_1's ndcg@5: 0.380973\n",
      "[110]\ttraining's ndcg@5: 0.452459\tvalid_1's ndcg@5: 0.380537\n",
      "[111]\ttraining's ndcg@5: 0.452849\tvalid_1's ndcg@5: 0.380605\n",
      "[112]\ttraining's ndcg@5: 0.45334\tvalid_1's ndcg@5: 0.380822\n",
      "[113]\ttraining's ndcg@5: 0.453902\tvalid_1's ndcg@5: 0.381135\n",
      "[114]\ttraining's ndcg@5: 0.454141\tvalid_1's ndcg@5: 0.381141\n",
      "[115]\ttraining's ndcg@5: 0.454532\tvalid_1's ndcg@5: 0.381174\n",
      "[116]\ttraining's ndcg@5: 0.455081\tvalid_1's ndcg@5: 0.381411\n",
      "[117]\ttraining's ndcg@5: 0.455436\tvalid_1's ndcg@5: 0.381673\n",
      "[118]\ttraining's ndcg@5: 0.455618\tvalid_1's ndcg@5: 0.381968\n",
      "[119]\ttraining's ndcg@5: 0.456107\tvalid_1's ndcg@5: 0.382287\n",
      "[120]\ttraining's ndcg@5: 0.456485\tvalid_1's ndcg@5: 0.38241\n",
      "[121]\ttraining's ndcg@5: 0.456964\tvalid_1's ndcg@5: 0.382701\n",
      "[122]\ttraining's ndcg@5: 0.457336\tvalid_1's ndcg@5: 0.38286\n",
      "[123]\ttraining's ndcg@5: 0.457823\tvalid_1's ndcg@5: 0.382791\n",
      "[124]\ttraining's ndcg@5: 0.458091\tvalid_1's ndcg@5: 0.382778\n",
      "[125]\ttraining's ndcg@5: 0.458548\tvalid_1's ndcg@5: 0.383118\n",
      "[126]\ttraining's ndcg@5: 0.458828\tvalid_1's ndcg@5: 0.383032\n",
      "[127]\ttraining's ndcg@5: 0.459106\tvalid_1's ndcg@5: 0.382762\n",
      "[128]\ttraining's ndcg@5: 0.459324\tvalid_1's ndcg@5: 0.383007\n",
      "[129]\ttraining's ndcg@5: 0.459844\tvalid_1's ndcg@5: 0.383121\n",
      "[130]\ttraining's ndcg@5: 0.460402\tvalid_1's ndcg@5: 0.38328\n",
      "[131]\ttraining's ndcg@5: 0.460762\tvalid_1's ndcg@5: 0.383335\n",
      "[132]\ttraining's ndcg@5: 0.460967\tvalid_1's ndcg@5: 0.383344\n",
      "[133]\ttraining's ndcg@5: 0.461298\tvalid_1's ndcg@5: 0.3835\n",
      "[134]\ttraining's ndcg@5: 0.461592\tvalid_1's ndcg@5: 0.383596\n",
      "[135]\ttraining's ndcg@5: 0.461908\tvalid_1's ndcg@5: 0.383462\n",
      "[136]\ttraining's ndcg@5: 0.462365\tvalid_1's ndcg@5: 0.383289\n",
      "[137]\ttraining's ndcg@5: 0.462723\tvalid_1's ndcg@5: 0.383392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138]\ttraining's ndcg@5: 0.463035\tvalid_1's ndcg@5: 0.383341\n",
      "[139]\ttraining's ndcg@5: 0.463402\tvalid_1's ndcg@5: 0.383638\n",
      "[140]\ttraining's ndcg@5: 0.463887\tvalid_1's ndcg@5: 0.383705\n",
      "[141]\ttraining's ndcg@5: 0.464127\tvalid_1's ndcg@5: 0.383422\n",
      "[142]\ttraining's ndcg@5: 0.464507\tvalid_1's ndcg@5: 0.383377\n",
      "[143]\ttraining's ndcg@5: 0.464749\tvalid_1's ndcg@5: 0.383349\n",
      "[144]\ttraining's ndcg@5: 0.465072\tvalid_1's ndcg@5: 0.383566\n",
      "[145]\ttraining's ndcg@5: 0.465426\tvalid_1's ndcg@5: 0.383284\n",
      "[146]\ttraining's ndcg@5: 0.465676\tvalid_1's ndcg@5: 0.383337\n",
      "[147]\ttraining's ndcg@5: 0.466024\tvalid_1's ndcg@5: 0.383733\n",
      "[148]\ttraining's ndcg@5: 0.466291\tvalid_1's ndcg@5: 0.383427\n",
      "[149]\ttraining's ndcg@5: 0.46666\tvalid_1's ndcg@5: 0.383583\n",
      "[150]\ttraining's ndcg@5: 0.467077\tvalid_1's ndcg@5: 0.383805\n",
      "[151]\ttraining's ndcg@5: 0.467615\tvalid_1's ndcg@5: 0.384001\n",
      "[152]\ttraining's ndcg@5: 0.468035\tvalid_1's ndcg@5: 0.384107\n",
      "[153]\ttraining's ndcg@5: 0.468389\tvalid_1's ndcg@5: 0.384349\n",
      "[154]\ttraining's ndcg@5: 0.468592\tvalid_1's ndcg@5: 0.383901\n",
      "[155]\ttraining's ndcg@5: 0.468831\tvalid_1's ndcg@5: 0.384109\n",
      "[156]\ttraining's ndcg@5: 0.469129\tvalid_1's ndcg@5: 0.384364\n",
      "[157]\ttraining's ndcg@5: 0.469713\tvalid_1's ndcg@5: 0.384562\n",
      "[158]\ttraining's ndcg@5: 0.470098\tvalid_1's ndcg@5: 0.384512\n",
      "[159]\ttraining's ndcg@5: 0.470487\tvalid_1's ndcg@5: 0.3846\n",
      "[160]\ttraining's ndcg@5: 0.470738\tvalid_1's ndcg@5: 0.384921\n",
      "[161]\ttraining's ndcg@5: 0.471007\tvalid_1's ndcg@5: 0.385068\n",
      "[162]\ttraining's ndcg@5: 0.471251\tvalid_1's ndcg@5: 0.385221\n",
      "[163]\ttraining's ndcg@5: 0.471705\tvalid_1's ndcg@5: 0.385149\n",
      "[164]\ttraining's ndcg@5: 0.472122\tvalid_1's ndcg@5: 0.385278\n",
      "[165]\ttraining's ndcg@5: 0.47236\tvalid_1's ndcg@5: 0.385192\n",
      "[166]\ttraining's ndcg@5: 0.472836\tvalid_1's ndcg@5: 0.385312\n",
      "[167]\ttraining's ndcg@5: 0.473193\tvalid_1's ndcg@5: 0.385362\n",
      "[168]\ttraining's ndcg@5: 0.473399\tvalid_1's ndcg@5: 0.385448\n",
      "[169]\ttraining's ndcg@5: 0.473785\tvalid_1's ndcg@5: 0.385685\n",
      "[170]\ttraining's ndcg@5: 0.474037\tvalid_1's ndcg@5: 0.38571\n",
      "[171]\ttraining's ndcg@5: 0.474441\tvalid_1's ndcg@5: 0.385972\n",
      "[172]\ttraining's ndcg@5: 0.474785\tvalid_1's ndcg@5: 0.386387\n",
      "[173]\ttraining's ndcg@5: 0.475017\tvalid_1's ndcg@5: 0.386345\n",
      "[174]\ttraining's ndcg@5: 0.475264\tvalid_1's ndcg@5: 0.386266\n",
      "[175]\ttraining's ndcg@5: 0.475608\tvalid_1's ndcg@5: 0.386158\n",
      "[176]\ttraining's ndcg@5: 0.47581\tvalid_1's ndcg@5: 0.386389\n",
      "[177]\ttraining's ndcg@5: 0.476186\tvalid_1's ndcg@5: 0.386636\n",
      "[178]\ttraining's ndcg@5: 0.476581\tvalid_1's ndcg@5: 0.38678\n",
      "[179]\ttraining's ndcg@5: 0.476878\tvalid_1's ndcg@5: 0.386659\n",
      "[180]\ttraining's ndcg@5: 0.477279\tvalid_1's ndcg@5: 0.386662\n",
      "[181]\ttraining's ndcg@5: 0.47756\tvalid_1's ndcg@5: 0.386639\n",
      "[182]\ttraining's ndcg@5: 0.477947\tvalid_1's ndcg@5: 0.386588\n",
      "[183]\ttraining's ndcg@5: 0.47812\tvalid_1's ndcg@5: 0.386443\n",
      "[184]\ttraining's ndcg@5: 0.478545\tvalid_1's ndcg@5: 0.386547\n",
      "[185]\ttraining's ndcg@5: 0.478786\tvalid_1's ndcg@5: 0.386562\n",
      "[186]\ttraining's ndcg@5: 0.479075\tvalid_1's ndcg@5: 0.386742\n",
      "[187]\ttraining's ndcg@5: 0.479415\tvalid_1's ndcg@5: 0.386616\n",
      "[188]\ttraining's ndcg@5: 0.479592\tvalid_1's ndcg@5: 0.386509\n",
      "[189]\ttraining's ndcg@5: 0.479849\tvalid_1's ndcg@5: 0.386582\n",
      "[190]\ttraining's ndcg@5: 0.480101\tvalid_1's ndcg@5: 0.386608\n",
      "[191]\ttraining's ndcg@5: 0.480445\tvalid_1's ndcg@5: 0.386728\n",
      "[192]\ttraining's ndcg@5: 0.48087\tvalid_1's ndcg@5: 0.386732\n",
      "[193]\ttraining's ndcg@5: 0.481134\tvalid_1's ndcg@5: 0.386975\n",
      "[194]\ttraining's ndcg@5: 0.481426\tvalid_1's ndcg@5: 0.386934\n",
      "[195]\ttraining's ndcg@5: 0.481625\tvalid_1's ndcg@5: 0.387425\n",
      "[196]\ttraining's ndcg@5: 0.482126\tvalid_1's ndcg@5: 0.387509\n",
      "[197]\ttraining's ndcg@5: 0.48244\tvalid_1's ndcg@5: 0.387718\n",
      "[198]\ttraining's ndcg@5: 0.482609\tvalid_1's ndcg@5: 0.387582\n",
      "[199]\ttraining's ndcg@5: 0.482781\tvalid_1's ndcg@5: 0.387635\n",
      "[200]\ttraining's ndcg@5: 0.483093\tvalid_1's ndcg@5: 0.387242\n",
      "[201]\ttraining's ndcg@5: 0.483521\tvalid_1's ndcg@5: 0.38743\n",
      "[202]\ttraining's ndcg@5: 0.483735\tvalid_1's ndcg@5: 0.387345\n",
      "[203]\ttraining's ndcg@5: 0.483924\tvalid_1's ndcg@5: 0.387422\n",
      "[204]\ttraining's ndcg@5: 0.484312\tvalid_1's ndcg@5: 0.387525\n",
      "[205]\ttraining's ndcg@5: 0.484523\tvalid_1's ndcg@5: 0.387529\n",
      "[206]\ttraining's ndcg@5: 0.484844\tvalid_1's ndcg@5: 0.387622\n",
      "[207]\ttraining's ndcg@5: 0.485035\tvalid_1's ndcg@5: 0.387673\n",
      "[208]\ttraining's ndcg@5: 0.485238\tvalid_1's ndcg@5: 0.387684\n",
      "[209]\ttraining's ndcg@5: 0.485603\tvalid_1's ndcg@5: 0.387641\n",
      "[210]\ttraining's ndcg@5: 0.485828\tvalid_1's ndcg@5: 0.387559\n",
      "[211]\ttraining's ndcg@5: 0.486055\tvalid_1's ndcg@5: 0.387711\n",
      "[212]\ttraining's ndcg@5: 0.486405\tvalid_1's ndcg@5: 0.387814\n",
      "[213]\ttraining's ndcg@5: 0.486619\tvalid_1's ndcg@5: 0.387776\n",
      "[214]\ttraining's ndcg@5: 0.486889\tvalid_1's ndcg@5: 0.38767\n",
      "[215]\ttraining's ndcg@5: 0.487341\tvalid_1's ndcg@5: 0.387376\n",
      "[216]\ttraining's ndcg@5: 0.487606\tvalid_1's ndcg@5: 0.387386\n",
      "[217]\ttraining's ndcg@5: 0.487928\tvalid_1's ndcg@5: 0.387383\n",
      "[218]\ttraining's ndcg@5: 0.488134\tvalid_1's ndcg@5: 0.387628\n",
      "[219]\ttraining's ndcg@5: 0.488409\tvalid_1's ndcg@5: 0.387745\n",
      "[220]\ttraining's ndcg@5: 0.488798\tvalid_1's ndcg@5: 0.387925\n",
      "[221]\ttraining's ndcg@5: 0.48909\tvalid_1's ndcg@5: 0.387737\n",
      "[222]\ttraining's ndcg@5: 0.4893\tvalid_1's ndcg@5: 0.387481\n",
      "[223]\ttraining's ndcg@5: 0.489574\tvalid_1's ndcg@5: 0.387445\n",
      "[224]\ttraining's ndcg@5: 0.489801\tvalid_1's ndcg@5: 0.387433\n",
      "[225]\ttraining's ndcg@5: 0.49013\tvalid_1's ndcg@5: 0.387646\n",
      "[226]\ttraining's ndcg@5: 0.490399\tvalid_1's ndcg@5: 0.387828\n",
      "[227]\ttraining's ndcg@5: 0.490667\tvalid_1's ndcg@5: 0.387627\n",
      "[228]\ttraining's ndcg@5: 0.490928\tvalid_1's ndcg@5: 0.387574\n",
      "[229]\ttraining's ndcg@5: 0.491155\tvalid_1's ndcg@5: 0.387372\n",
      "[230]\ttraining's ndcg@5: 0.49131\tvalid_1's ndcg@5: 0.387361\n",
      "[231]\ttraining's ndcg@5: 0.49161\tvalid_1's ndcg@5: 0.387303\n",
      "[232]\ttraining's ndcg@5: 0.491914\tvalid_1's ndcg@5: 0.387371\n",
      "[233]\ttraining's ndcg@5: 0.492134\tvalid_1's ndcg@5: 0.387762\n",
      "[234]\ttraining's ndcg@5: 0.492327\tvalid_1's ndcg@5: 0.387722\n",
      "[235]\ttraining's ndcg@5: 0.492646\tvalid_1's ndcg@5: 0.387753\n",
      "[236]\ttraining's ndcg@5: 0.492984\tvalid_1's ndcg@5: 0.387728\n",
      "[237]\ttraining's ndcg@5: 0.493156\tvalid_1's ndcg@5: 0.387737\n",
      "[238]\ttraining's ndcg@5: 0.493343\tvalid_1's ndcg@5: 0.3879\n",
      "[239]\ttraining's ndcg@5: 0.493714\tvalid_1's ndcg@5: 0.387697\n",
      "[240]\ttraining's ndcg@5: 0.494008\tvalid_1's ndcg@5: 0.387995\n",
      "[241]\ttraining's ndcg@5: 0.49421\tvalid_1's ndcg@5: 0.388161\n",
      "[242]\ttraining's ndcg@5: 0.494445\tvalid_1's ndcg@5: 0.387911\n",
      "[243]\ttraining's ndcg@5: 0.494716\tvalid_1's ndcg@5: 0.387891\n",
      "[244]\ttraining's ndcg@5: 0.494938\tvalid_1's ndcg@5: 0.387868\n",
      "[245]\ttraining's ndcg@5: 0.495132\tvalid_1's ndcg@5: 0.387821\n",
      "[246]\ttraining's ndcg@5: 0.495415\tvalid_1's ndcg@5: 0.387717\n",
      "[247]\ttraining's ndcg@5: 0.495703\tvalid_1's ndcg@5: 0.387739\n",
      "[248]\ttraining's ndcg@5: 0.49609\tvalid_1's ndcg@5: 0.387914\n",
      "[249]\ttraining's ndcg@5: 0.496383\tvalid_1's ndcg@5: 0.387985\n",
      "[250]\ttraining's ndcg@5: 0.496564\tvalid_1's ndcg@5: 0.388164\n",
      "[251]\ttraining's ndcg@5: 0.49671\tvalid_1's ndcg@5: 0.388183\n",
      "[252]\ttraining's ndcg@5: 0.496974\tvalid_1's ndcg@5: 0.388187\n",
      "[253]\ttraining's ndcg@5: 0.497219\tvalid_1's ndcg@5: 0.388072\n",
      "[254]\ttraining's ndcg@5: 0.497526\tvalid_1's ndcg@5: 0.388181\n",
      "[255]\ttraining's ndcg@5: 0.497779\tvalid_1's ndcg@5: 0.38808\n",
      "[256]\ttraining's ndcg@5: 0.498065\tvalid_1's ndcg@5: 0.388107\n",
      "[257]\ttraining's ndcg@5: 0.498278\tvalid_1's ndcg@5: 0.388374\n",
      "[258]\ttraining's ndcg@5: 0.498488\tvalid_1's ndcg@5: 0.388148\n",
      "[259]\ttraining's ndcg@5: 0.498728\tvalid_1's ndcg@5: 0.388139\n",
      "[260]\ttraining's ndcg@5: 0.498946\tvalid_1's ndcg@5: 0.387968\n",
      "[261]\ttraining's ndcg@5: 0.499176\tvalid_1's ndcg@5: 0.38798\n",
      "[262]\ttraining's ndcg@5: 0.499323\tvalid_1's ndcg@5: 0.388032\n",
      "[263]\ttraining's ndcg@5: 0.499459\tvalid_1's ndcg@5: 0.388096\n",
      "[264]\ttraining's ndcg@5: 0.499812\tvalid_1's ndcg@5: 0.387918\n",
      "[265]\ttraining's ndcg@5: 0.500063\tvalid_1's ndcg@5: 0.387923\n",
      "[266]\ttraining's ndcg@5: 0.500288\tvalid_1's ndcg@5: 0.387918\n",
      "[267]\ttraining's ndcg@5: 0.50048\tvalid_1's ndcg@5: 0.387995\n",
      "[268]\ttraining's ndcg@5: 0.500885\tvalid_1's ndcg@5: 0.38823\n",
      "[269]\ttraining's ndcg@5: 0.501079\tvalid_1's ndcg@5: 0.388068\n",
      "[270]\ttraining's ndcg@5: 0.501356\tvalid_1's ndcg@5: 0.388116\n",
      "[271]\ttraining's ndcg@5: 0.501544\tvalid_1's ndcg@5: 0.38817\n",
      "[272]\ttraining's ndcg@5: 0.501874\tvalid_1's ndcg@5: 0.388298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273]\ttraining's ndcg@5: 0.502141\tvalid_1's ndcg@5: 0.388422\n",
      "[274]\ttraining's ndcg@5: 0.502367\tvalid_1's ndcg@5: 0.388224\n",
      "[275]\ttraining's ndcg@5: 0.502514\tvalid_1's ndcg@5: 0.388258\n",
      "[276]\ttraining's ndcg@5: 0.502728\tvalid_1's ndcg@5: 0.388299\n",
      "[277]\ttraining's ndcg@5: 0.502997\tvalid_1's ndcg@5: 0.388318\n",
      "[278]\ttraining's ndcg@5: 0.503246\tvalid_1's ndcg@5: 0.388656\n",
      "[279]\ttraining's ndcg@5: 0.503493\tvalid_1's ndcg@5: 0.388593\n",
      "[280]\ttraining's ndcg@5: 0.503694\tvalid_1's ndcg@5: 0.388832\n",
      "[281]\ttraining's ndcg@5: 0.503926\tvalid_1's ndcg@5: 0.388837\n",
      "[282]\ttraining's ndcg@5: 0.504135\tvalid_1's ndcg@5: 0.388724\n",
      "[283]\ttraining's ndcg@5: 0.504293\tvalid_1's ndcg@5: 0.388764\n",
      "[284]\ttraining's ndcg@5: 0.504441\tvalid_1's ndcg@5: 0.38872\n",
      "[285]\ttraining's ndcg@5: 0.504629\tvalid_1's ndcg@5: 0.388917\n",
      "[286]\ttraining's ndcg@5: 0.504818\tvalid_1's ndcg@5: 0.388812\n",
      "[287]\ttraining's ndcg@5: 0.504997\tvalid_1's ndcg@5: 0.388738\n",
      "[288]\ttraining's ndcg@5: 0.505277\tvalid_1's ndcg@5: 0.38886\n",
      "[289]\ttraining's ndcg@5: 0.505524\tvalid_1's ndcg@5: 0.388639\n",
      "[290]\ttraining's ndcg@5: 0.505758\tvalid_1's ndcg@5: 0.388539\n",
      "[291]\ttraining's ndcg@5: 0.50598\tvalid_1's ndcg@5: 0.388456\n",
      "[292]\ttraining's ndcg@5: 0.506214\tvalid_1's ndcg@5: 0.388551\n",
      "[293]\ttraining's ndcg@5: 0.506493\tvalid_1's ndcg@5: 0.388593\n",
      "[294]\ttraining's ndcg@5: 0.506681\tvalid_1's ndcg@5: 0.38879\n",
      "[295]\ttraining's ndcg@5: 0.506873\tvalid_1's ndcg@5: 0.388868\n",
      "[296]\ttraining's ndcg@5: 0.507031\tvalid_1's ndcg@5: 0.388743\n",
      "[297]\ttraining's ndcg@5: 0.507219\tvalid_1's ndcg@5: 0.388812\n",
      "[298]\ttraining's ndcg@5: 0.507357\tvalid_1's ndcg@5: 0.388742\n",
      "[299]\ttraining's ndcg@5: 0.507612\tvalid_1's ndcg@5: 0.389083\n",
      "[300]\ttraining's ndcg@5: 0.507815\tvalid_1's ndcg@5: 0.389102\n",
      "CPU times: user 13min 45s, sys: 43.1 s, total: 14min 28s\n",
      "Wall time: 4min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(learning_rate=0.05, metric='ndcg', n_estimators=300,\n",
       "           objective='lambdarank', subsample=0.9, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model7.fit(X_train, y_train_, eval_set=[(X_train, y_train_), (X_test, y_test_)], eval_group=[X_train['srch_id'].value_counts(sort=False).sort_index(), X_test['srch_id'].value_counts(sort=False).sort_index()], group=X_train['srch_id'].value_counts(sort=False).sort_index(),\n",
    "            eval_at=5,categorical_feature=rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47556197, -0.89544195, -0.67214764, ..., -0.36919047,\n",
       "        0.06262034,  0.52796963])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_7 = model7.predict(X_test)\n",
    "y_pred_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([X_test[\"srch_id\"], pos.iloc[test_inds]], axis=1)\n",
    "df['predictions'] = y_pred_7\n",
    "# df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37192940880814823\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in df['srch_id'].unique():\n",
    "    a1 = [df[df[\"srch_id\"]==i][\"position\"].values]\n",
    "    a2 = [df[df[\"srch_id\"]==i][\"predictions\"].values]\n",
    "    scores.append(ndcg_score(a1, a2, k=5))\n",
    "print(sum(scores)/len(scores)) #should be better than 0,373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-07e685cc273c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m--> 687\u001b[0;31m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[0m\u001b[1;32m    688\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2957\u001b[0;31m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0m\u001b[1;32m   2958\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input data must be 2 dimensional and non empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mcat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mcat_cols_not_ordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_cols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   4123\u001b[0m         \u001b[0;36m4\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \"\"\"\n\u001b[0;32m-> 4125\u001b[0;31m         return super().rename(\n\u001b[0m\u001b[1;32m   4126\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacements\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5809\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5810\u001b[0m         \"\"\"\n\u001b[0;32m-> 5811\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5812\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred7 = model7.predict(test)\n",
    "y_pred7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- by target_score (click_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(data = -y_pred66, columns=['target_score']) #replace with y_pred7\n",
    "r.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"srch_id\"] = test['srch_id']\n",
    "r[\"prop_id\"] = test['prop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.sort_values(['srch_id','target_score'])[[\"srch_id\",\"prop_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"sub14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tCatBoost https://colab.research.google.com/drive/1cuFTgBFRVFD8dVP74QkhNZ_9v7sDgx_z \n",
    "\n",
    "https://www.kaggle.com/code/danofer/catboost-ranking-ncdg-expedia-search-queries \n",
    "-\tTF listwise https://www.tensorflow.org/ranking "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
